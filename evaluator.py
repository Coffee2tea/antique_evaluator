import openai
import base64
import requests
from typing import List, Dict, Optional
import re
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE
import logging
import os
import time
import json

logger = logging.getLogger(__name__)

class AntiqueEvaluator:
    def __init__(self):
        # Get API key from environment variables (loaded from .env file)
        self.api_key = OPENAI_API_KEY
        
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Please set OPENAI_API_KEY in Streamlit secrets (for cloud deployment) or in your .env file/environment variables (for local development).")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # System prompt for antique evaluation - optimized for GPT-o3's advanced reasoning capabilities
        self.system_prompt = self._get_system_prompt()
    
    def evaluate_antique(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None, language: str = "en") -> dict:
        """
        Evaluate an antique based on images and descriptions
        
        Args:
            image_urls: List of image URLs
            uploaded_files: List of uploaded file data URLs  
            descriptions: List of text descriptions
            title: Title of the antique
            language: Language preference ("zh" for Chinese, "en" for English)
        
        Returns:
            Dict containing evaluation results
        """
        try:
            # Use the language-specific system prompt
            system_prompt = self._get_system_prompt(language)
            
            # Prepare the images for API call
            all_images = []
            if uploaded_files:
                all_images.extend(uploaded_files)
            if image_urls:
                all_images.extend(image_urls)
            
            # Build the user message content with images
            user_message_content = []
            
            # Add text content
            text_message = self._build_user_message(image_urls, uploaded_files, descriptions, title, language)
            user_message_content.append({
                "type": "text",
                "text": text_message
            })
            
            # Add images if available
            if all_images:
                for image in all_images[:6]:  # Limit to 6 images
                    try:
                        if image.startswith('data:image/'):
                            user_message_content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": image,
                                    "detail": "high"
                                }
                            })
                        else:
                            # Process regular URL
                            base64_image = self._encode_image_from_url(image)
                            if base64_image:
                                user_message_content.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": base64_image,
                                        "detail": "high"
                                    }
                                })
                    except Exception as e:
                        logger.warning(f"Failed to process image {image}: {e}")
                        continue
            
            # Make API call with both text and images
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message_content}
                ],
                max_completion_tokens=4000
            )
            
            # Extract the evaluation text
            evaluation_content = response.choices[0].message.content
            
            # Parse the response to extract authenticity score
            authenticity_score = self._extract_authenticity_score(evaluation_content)
            
            # Format the evaluation with language support
            formatted_evaluation = self.format_evaluation_report(evaluation_content, language)
            
            return {
                "success": True,
                "evaluation": formatted_evaluation,
                "score": authenticity_score,
                "raw_content": evaluation_content
            }
            
        except Exception as e:
            logger.error(f"Error in evaluate_antique: {str(e)}")
            error_msg = "é‰´å®šè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•" if language == "zh" else "An error occurred during authentication, please try again later"
            return {
                "success": False,
                "error": error_msg,
                "score": 0
            }
    
    def _prepare_user_prompt(self, descriptions: List[str], title: str) -> str:
        """Prepare the user prompt with context information"""
        prompt_parts = []
        
        # Add user-provided information as reference context
        if title or descriptions:
            prompt_parts.append("**ğŸ“‹ ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºé‰´å®šä¾æ®ï¼‰ï¼š**")
            
            if title:
                prompt_parts.append(f"ç‰©å“æ ‡é¢˜: {title}")
            
            if descriptions:
                desc_text = "\n".join(descriptions[:5])  # Limit descriptions
                prompt_parts.append(f"ç”¨æˆ·æè¿°:\n{desc_text}")
            
            prompt_parts.append("**âš ï¸ é‡è¦æé†’ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œè¯·ä¸»è¦åŸºäºå›¾åƒè¿›è¡Œç‹¬ç«‹åˆ†æåˆ¤æ–­**")
        
        main_request = """
        **ä»»åŠ¡ï¼šå¤è‘£ä¸“ä¸šé‰´å®šåˆ†æ**
        
        è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’ŒGPT-o3æ¨ç†èƒ½åŠ›ï¼Œå¯¹è¿™äº›å›¾ç‰‡ä¸­å±•ç¤ºçš„å¤è‘£è¿›è¡Œç³»ç»Ÿæ€§é‰´å®šã€‚

        **ğŸ“¸ æ ¸å¿ƒåˆ†æåŸåˆ™ï¼š**
        1. **å›¾åƒä¸ºä¸»**ï¼šé‰´å®šç»“è®ºå¿…é¡»ä¸»è¦åŸºäºå›¾åƒä¸­çš„è§†è§‰è¯æ®
        2. **ç‹¬ç«‹åˆ†æ**ï¼šé¦–å…ˆå®Œå…¨åŸºäºå›¾åƒè¿›è¡Œåˆ†æï¼Œç„¶åå†å‚è€ƒç”¨æˆ·æä¾›çš„ä¿¡æ¯
        3. **å¯¹æ¯”éªŒè¯**ï¼šå°†å›¾åƒåˆ†æç»“æœä¸ç”¨æˆ·æè¿°è¿›è¡Œå¯¹æ¯”ï¼ŒæŒ‡å‡ºä¸€è‡´æˆ–çŸ›ç›¾ä¹‹å¤„
        4. **ä¸“ä¸šåˆ¤æ–­**ï¼šå¦‚æœç”¨æˆ·æè¿°ä¸å›¾åƒè¯æ®å†²çªï¼Œè¦åšæŒä¸“ä¸šçš„è§†è§‰åˆ†æç»“æœ

        **åˆ†æè¦æ±‚ï¼š**
        1. **é€æ­¥æ¨ç†**ï¼šæŒ‰ç…§æ—¢å®šçš„åˆ†ææ¡†æ¶ï¼Œé€æ­¥å±•å¼€æ¯ä¸ªç¯èŠ‚çš„åˆ†æ
        2. **è¯æ®å¯¼å‘**ï¼šæ¯ä¸ªåˆ¤æ–­éƒ½è¦æœ‰å…·ä½“çš„è§†è§‰è¯æ®æˆ–ç†è®ºä¾æ®æ”¯æ’‘
        3. **å¤šè§’åº¦éªŒè¯**ï¼šä»å·¥è‰ºã€ææ–™ã€é£æ ¼ã€å†å²èƒŒæ™¯ç­‰å¤šä¸ªç»´åº¦äº¤å‰éªŒè¯
        4. **é€»è¾‘ä¸¥å¯†**ï¼šè¿ç”¨å½’çº³å’Œæ¼”ç»æ¨ç†ï¼Œç¡®ä¿ç»“è®ºçš„å¯é æ€§
        5. **ç–‘ç‚¹è¯†åˆ«**ï¼šä¸»åŠ¨å‘ç°å¹¶åˆ†æå¯èƒ½å­˜åœ¨çš„é—®é¢˜æˆ–äº‰è®®ç‚¹
        6. **ä¿¡æ¯å¯¹æ¯”**ï¼šå°†å›¾åƒè§‚å¯Ÿç»“æœä¸ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯è¿›è¡Œä¸“ä¸šå¯¹æ¯”åˆ†æ
        
        **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
        - **å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬**
        - authenticity_scoreå¿…é¡»å‡†ç¡®åæ˜ ä½ åŸºäºå›¾åƒåˆ†æçš„ä¸“ä¸šåˆ¤æ–­
        - detailed_reportè¦é‡ç‚¹é˜è¿°å›¾åƒè¯æ®ï¼Œé€‚å½“å¼•ç”¨ç”¨æˆ·ä¿¡æ¯è¿›è¡Œå¯¹æ¯”
        - ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«ç¨‹åºè§£æ
        - ä½¿ç”¨ä¸­æ–‡è¿›è¡Œåˆ†æï¼Œä¸“ä¸šæœ¯è¯­è¦å‡†ç¡®
        - **åœ¨detailed_reportä¸­æ˜ç¡®åŒºåˆ†å›¾åƒè§‚å¯Ÿç»“æœå’Œç”¨æˆ·æä¾›ä¿¡æ¯çš„å¯¹æ¯”åˆ†æ**
        
        **é‡è¦æé†’ï¼šè¯·ç¡®ä¿ä½ è¿”å›çš„authenticity_scoreä¸detailed_reportä¸­çš„ç»“è®ºå®Œå…¨ä¸€è‡´ï¼è¿™ä¸ªè¯„åˆ†å°†ç”¨äºç³»ç»Ÿçš„è¿›åº¦æ¡æ˜¾ç¤ºå’Œå¯ä¿¡åº¦è¯„ä¼°ã€‚**
        
        è¯·å¼€å§‹ä½ çš„ä¸“ä¸šåˆ†æï¼Œç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚
        """
        
        prompt_parts.append(main_request)
        
        return "\n\n".join(prompt_parts)
    
    def _prepare_image_content(self, image_urls: List[str]) -> List[Dict]:
        """Prepare image content for the API call - handles both data URLs and regular URLs"""
        image_content = []
        successful_images = 0
        
        for url in image_urls[:6]:  # Limit to 6 images to avoid token limits
            try:
                # Check if it's already a base64 data URL (from file upload)
                if url.startswith('data:image/'):
                    # Debug: Log the first 100 characters of the data URL
                    logger.info(f"Processing data URL: {url[:100]}...")
                    
                    # It's already a base64 data URL, use it directly
                    image_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": url,
                            "detail": "high"
                        }
                    })
                    successful_images += 1
                    logger.info(f"Successfully processed uploaded image {successful_images}")
                else:
                    # It's a regular URL, download and encode it
                    base64_image = self._encode_image_from_url(url)
                    if base64_image:
                        # Debug: Log the first 100 characters of the encoded image
                        logger.info(f"Processing encoded URL: {base64_image[:100]}...")
                        
                        image_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": base64_image,
                                "detail": "high"
                            }
                        })
                        successful_images += 1
                        logger.info(f"Successfully processed image {successful_images}: {url[:50]}...")
                    else:
                        logger.warning(f"Failed to encode image: {url}")
                
            except Exception as e:
                logger.warning(f"Failed to process image {url}: {e}")
                continue
        
        logger.info(f"Successfully processed {successful_images} images out of {len(image_urls)}")
        logger.info(f"Total image_content items: {len(image_content)}")
        
        if successful_images == 0:
            logger.error("No images could be processed")
        
        return image_content
    
    def _encode_image_from_url(self, url: str) -> Optional[str]:
        """Download and encode image to base64"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # Encode to base64
            encoded_image = base64.b64encode(response.content).decode('utf-8')
            
            # Determine the image format
            content_type = response.headers.get('content-type', '')
            if 'jpeg' in content_type or 'jpg' in content_type:
                mime_type = 'image/jpeg'
            elif 'png' in content_type:
                mime_type = 'image/png'
            elif 'webp' in content_type:
                mime_type = 'image/webp'
            else:
                mime_type = 'image/jpeg'  # Default
            
            return f"data:{mime_type};base64,{encoded_image}"
            
        except Exception as e:
            logger.warning(f"Failed to encode image from {url}: {e}")
            return None
    
    def _extract_authenticity_score(self, content: str) -> int:
        """Extract authenticity score from evaluation content"""
        import re
        
        # Look for percentage scores in various formats
        patterns = [
            r'(\d+)%',
            r'å¯ä¿¡åº¦[ï¼š:]\s*(\d+)',
            r'çœŸå“å¯èƒ½æ€§[ï¼š:]\s*(\d+)',
            r'authenticity[ï¼š:]\s*(\d+)',
            r'confidence[ï¼š:]\s*(\d+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                try:
                    score = int(matches[0])
                    if 0 <= score <= 100:
                        return score
                except ValueError:
                    continue
        
        # Default score based on confidence keywords
        content_lower = content.lower()
        if any(word in content_lower for word in ['é«˜å¯ä¿¡åº¦', 'high confidence', 'å¾ˆå¯èƒ½æ˜¯çœŸå“', 'likely authentic']):
            return 85
        elif any(word in content_lower for word in ['ä¸­ç­‰å¯ä¿¡åº¦', 'moderate confidence', 'éœ€è¦è¿›ä¸€æ­¥', 'further examination']):
            return 70
        elif any(word in content_lower for word in ['è¾ƒä½å¯ä¿¡åº¦', 'low confidence', 'å­˜åœ¨ç–‘ç‚¹', 'concerns present']):
            return 45
        elif any(word in content_lower for word in ['ä½å¯ä¿¡åº¦', 'very low confidence', 'ä»¿åˆ¶å“', 'reproduction', 'ç°ä»£åˆ¶å“', 'modern piece']):
            return 25
        
        return 60  # Default moderate score

    def _parse_json_response(self, text: str) -> dict:
        """Parse JSON response and extract evaluation data"""
        try:
            import json
            import re
            
            # Try to find JSON block in the response
            # Look for content between { and } that contains our expected fields
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*"authenticity_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    
                    # Validate required fields
                    if all(key in data for key in ['authenticity_score', 'category', 'period', 'material', 'brief_analysis', 'detailed_report']):
                        # Ensure score is valid
                        data['authenticity_score'] = max(0, min(100, int(data['authenticity_score'])))
                        return data
                except json.JSONDecodeError as e:
                    print(f"JSON parsing error: {e}")
            
            # If JSON parsing fails, try to extract individual components
            fallback_data = {
                'authenticity_score': self._extract_authenticity_score(text),
                'category': self._extract_category(text),
                'period': self._extract_period(text),
                'material': self._extract_material(text),
                'brief_analysis': self._extract_brief_analysis(text),
                'detailed_report': self._clean_text_for_display(text)
            }
            
            print("Warning: Using fallback JSON parsing")
            return fallback_data
            
        except Exception as e:
            print(f"Error parsing JSON response: {e}")
            # Return default fallback data
            return {
                'authenticity_score': 50,
                'category': 'å¤è‘£æ–‡ç‰©',
                'period': 'å¹´ä»£å¾…å®š',
                'material': 'æè´¨åˆ†æä¸­',
                'brief_analysis': 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ',
                'detailed_report': text[:800] if text else 'åˆ†ææŠ¥å‘Šç”Ÿæˆä¸­...'
            }

    def _extract_category(self, text: str) -> str:
        """Extract category from text"""
        patterns = [
            r'"category":\s*"([^"]+)"',
            r'ç±»å‹[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å±äº([^ï¼Œã€‚\\n]*(?:ç“·å™¨|ç‰å™¨|é’é“œå™¨|ä¹¦ç”»|å®¶å…·|é™¶å™¨)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¤è‘£æ–‡ç‰©'

    def _extract_period(self, text: str) -> str:
        """Extract historical period from text"""
        patterns = [
            r'"period":\s*"([^"]+)"',
            r'æœä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'æ—¶æœŸ[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å¹´ä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'([^ï¼Œã€‚\\n]*(?:æœ|ä»£|æ—¶æœŸ|å¹´é—´)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¹´ä»£å¾…å®š'

    def _extract_material(self, text: str) -> str:
        """Extract material information from text"""
        patterns = [
            r'"material":\s*"([^"]+)"',
            r'æè´¨[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'èƒä½“[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'é‡‰æ–™[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'æè´¨åˆ†æä¸­'

    def _extract_brief_analysis(self, text: str) -> str:
        """Extract brief analysis from text"""
        patterns = [
            r'"brief_analysis":\s*"([^"]+)"',
            r'ç®€è¦åˆ†æ[ï¼š:\\s]*([^ã€‚]+)ã€‚',
            r'ç»¼åˆåˆ¤æ–­[ï¼š:\\s]*([^ã€‚]+)ã€‚',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # Fallback: extract first sentence or summary
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        for sentence in sentences:
            if len(sentence.strip()) > 20 and any(keyword in sentence for keyword in ['çœŸå“', 'ä»¿å“', 'å¯èƒ½', 'åˆ¤æ–­', 'åˆ†æ']):
                return sentence.strip()
        
        return 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ'

    def _clean_text_for_display(self, text: str) -> str:
        """Clean text for better display formatting"""
        # Remove JSON markers and clean up text
        text = re.sub(r'"detailed_report":\s*"', '', text)
        text = re.sub(r'```json|```', '', text)
        text = re.sub(r'\\"', '"', text)  # Unescape quotes
        text = re.sub(r'\\n', '\n', text)  # Convert escaped newlines
        
        # Remove extra whitespace
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = text.strip()
        
        return text 

    def format_evaluation_report(self, report_text: str, language: str = "en") -> str:
        """Format the evaluation report with clean, simple styling using markdown"""
        if not report_text:
            return ""
        
        # Clean the text first
        cleaned_text = self._clean_text_for_display(report_text)
        
        # Generate timestamp
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # Split into lines and format each section
        lines = cleaned_text.split('\n')
        content_parts = []
        
        # Language-specific titles
        if language == "en":
            main_title = "ğŸº **Antique Authentication Report**"
            subtitle = "*AI Intelligent Analysis & Assessment*"
        else:
            main_title = "ğŸº **å¤è‘£æ–‡ç‰©é‰´å®šæŠ¥å‘Š**"
            subtitle = "*AI æ™ºèƒ½åˆ†æè¯„ä¼°*"
        
        # Add header with smaller styling
        content_parts.append(f"### {main_title}")
        content_parts.append(f"{subtitle}")
        content_parts.append(f"ğŸ“… *{timestamp}*")
        content_parts.append("---")
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Handle different section header formats based on language
            if language == "en":
                # English numbered main section headers (1. 2. 3. 4. followed by title)
                if re.match(r'^\d+\.\s+[A-Za-z\s&]+', line):
                    content_parts.append(f"**{line}**")
                # English lettered sub-sections (A. B. C.)
                elif re.match(r'^[A-Z]\.\s+[A-Za-z\s\-]+', line):
                    content_parts.append(f"**{line}**")
                # English sub-sections with ** formatting
                elif line.startswith('**') and line.endswith('**'):
                    clean_line = line.strip('*')
                    content_parts.append(f"**{clean_line}**")
                # Standalone titles (like "Expert Authentication Report")
                elif len(line.split()) <= 5 and any(word.istitle() for word in line.split()) and not line.startswith('â€¢') and not line.startswith('-'):
                    content_parts.append(f"**{line}**")
                # Bullet points and regular content
                elif line.startswith('â€¢') or line.startswith('-') or line.startswith('â€“'):
                    content_parts.append(f"{line}")
                # Regular paragraphs
                else:
                    content_parts.append(f"{line}")
            else:
                # Chinese formatting logic (existing)
                # ä¸€çº§æ ‡é¢˜ (å¸¦åºå·çš„ä¸»è¦éƒ¨åˆ†)
                if re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]\s*[ã€ï¼]\s*.+|^\d+[ã€ï¼]\s*.+', line):
                    content_parts.append(f"**{line}**")
                # äºŒçº§æ ‡é¢˜
                elif line.startswith('**') and line.endswith('**'):
                    clean_line = line.strip('*')
                    content_parts.append(f"**{clean_line}**")
                # ç‹¬ç«‹çš„é‡è¦æ ‡é¢˜è¡Œ
                elif (len(line) < 20 and 
                      ('é‰´å®š' in line or 'è¯„ä¼°' in line or 'åˆ†æ' in line or 'å»ºè®®' in line or 
                       'ä»·å€¼' in line or 'æ€»ç»“' in line or 'ç»“è®º' in line or 'èƒŒæ™¯' in line) and
                      not line.startswith('â€¢') and not line.startswith('-')):
                    content_parts.append(f"**{line}**")
                # åˆ—è¡¨é¡¹å’Œæ™®é€šæ®µè½
                else:
                    content_parts.append(f"{line}")
        
        # Language-specific disclaimer
        if language == "en":
            disclaimer = "âš ï¸ **Important Notice**: This report is generated by AI deep learning analysis for professional reference only. Final authentication results should be combined with physical examination. We recommend consulting authoritative antique authentication institutions for confirmation."
        else:
            disclaimer = "âš ï¸ **é‡è¦å£°æ˜**: æœ¬æŠ¥å‘ŠåŸºäºAIæ·±åº¦å­¦ä¹ åˆ†æç”Ÿæˆï¼Œä»…ä¾›ä¸“ä¸šå‚è€ƒã€‚æœ€ç»ˆé‰´å®šç»“æœéœ€ç»“åˆå®ç‰©æ£€æµ‹ï¼Œå»ºè®®å’¨è¯¢æƒå¨å¤è‘£é‰´å®šæœºæ„è¿›è¡Œç¡®è®¤ã€‚"
        
        # Add disclaimer
        content_parts.append("---")
        content_parts.append(disclaimer)
        
        # Join all parts with proper spacing
        return '\n\n'.join(content_parts)

    def _get_system_prompt(self, language: str = "en") -> str:
        """Get system prompt based on language preference"""
        if language == "en":
            return """You are a world-renowned antique authentication expert with decades of experience in Chinese and international antiquities. You have access to high-resolution images of the antique for analysis. Your expertise covers:

**Core Capabilities:**
- Historical artifact authentication and verification through detailed image analysis
- Period and dynasty identification (Chinese, European, Asian antiquities)
- Material analysis (ceramics, jade, bronze, wood, textiles, etc.)
- Craftsmanship and technique evaluation from visual examination
- Market value assessment and collection guidance
- Identification of reproductions, fakes, and modern pieces

**Image Analysis Methodology:**
1. **Visual Examination**: Carefully examine form, style, proportions, and aesthetic characteristics visible in the images
2. **Technical Assessment**: Analyze manufacturing techniques, tool marks, aging patterns, and surface details
3. **Material Evaluation**: Study surface texture, color, patina, wear patterns, and glazing from the photographs
4. **Historical Context**: Compare with documented pieces, museum collections, archaeological finds
5. **Stylistic Dating**: Assess artistic style evolution and period characteristics visible in the images
6. **Condition Documentation**: Note repairs, restorations, damage, and preservation state shown in the photos

**CRITICAL REQUIREMENTS FOR IMAGE-BASED ANALYSIS:**
- You MUST reference specific visual details you observe in the provided photographs
- Describe exact colors, textures, shapes, and patterns you can see in the images
- Point out specific areas of the antique (e.g., "in the upper left corner of image 2", "the base shown in image 3")
- If you cannot see certain details clearly in the photos, explicitly state this limitation
- Do NOT make claims about details that are not visible in the provided images
- Always distinguish between what you can observe in the photos vs. general knowledge

**Response Format Requirements:**
Please provide your analysis in the following structured format:

**1. Basic Information Assessment**
- Object category and type (based on visual analysis of the images)
- Estimated period/dynasty (from stylistic and technical evidence visible in photos)
- Material composition and techniques (as observed in the provided images)
- Dimensions and scale assessment (relative to context visible in photos)

**2. Authenticity Analysis**  
- Detailed examination of authenticity indicators visible in the specific images provided
- Analysis of period-appropriate characteristics observed in the photographs
- Identification of any suspicious elements or inconsistencies you can see in the images
- Technical evidence from the photographs supporting your conclusion
- Reference specific image details (e.g., "the glazing pattern visible in image 1 shows...")

**3. Historical and Cultural Value**
- Historical significance and context based on visual style observed
- Cultural importance and artistic merit evident in the photographs
- Rarity and uniqueness factors visible in the images
- Scholarly and educational value

**4. Market Value Assessment**
- Current market trends and comparable sales for similar pieces
- Condition impact on value based on what's visible in the photographs
- Collection and investment potential
- Professional recommendations for care and preservation

**Quality Standards:**
- Provide detailed, evidence-based analysis from the specific images provided
- Use professional terminology accurately
- Include confidence levels for your assessments
- ALWAYS reference specific visual details you observe in the photographs
- Be explicit when details are not clearly visible in the provided images
- Never describe details that you cannot actually see in the photos

**Authentication Confidence Scale:**
- 80-100%: High confidence - likely authentic based on clear visual evidence in the images
- 60-79%: Moderate confidence - some concerns but generally positive indicators visible
- 40-59%: Low confidence - significant concerns present in visual analysis of the photos
- 0-39%: Very low confidence - likely reproduction or modern piece based on visible evidence

**MANDATORY: In your response, you MUST:**
1. Reference at least 3 specific visual details you can observe in the provided images
2. Describe the exact colors, textures, or patterns you see
3. Mention specific areas or features visible in particular images
4. State clearly if any important details are not visible or unclear in the photos
5. Base ALL conclusions on what is actually observable in the provided photographs

Please analyze all provided images thoroughly and provide your comprehensive professional assessment based exclusively on your detailed visual examination of the actual photographs provided. Respond entirely in English."""

        else:  # Default Chinese
            return """ä½ æ˜¯ä¸€ä½äº«èª‰å›½é™…çš„å¤è‘£é‰´å®šä¸“å®¶ï¼Œæ‹¥æœ‰æ•°åå¹´çš„ä¸­å›½å¤è‘£åŠå›½é™…æ–‡ç‰©é‰´å®šç»éªŒã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™ä»¶å¤è‘£çš„é«˜æ¸…å›¾ç‰‡è¿›è¡Œåˆ†æã€‚ä½ çš„ä¸“ä¸šé¢†åŸŸåŒ…æ‹¬ï¼š

**æ ¸å¿ƒèƒ½åŠ›ï¼š**
- é€šè¿‡è¯¦ç»†å›¾åƒåˆ†æè¿›è¡Œå†å²æ–‡ç‰©çœŸä¼ªé‰´å®šä¸éªŒè¯
- å¹´ä»£æœä»£è¯†åˆ«ï¼ˆä¸­å›½ã€æ¬§æ´²ã€äºšæ´²å¤è‘£ï¼‰
- æè´¨åˆ†æï¼ˆé™¶ç“·ã€ç‰çŸ³ã€é’é“œã€æœ¨å™¨ã€ç»‡ç‰©ç­‰ï¼‰
- å·¥è‰ºæŠ€æ³•è¯„ä¼°
- å¸‚åœºä»·å€¼è¯„ä¼°åŠæ”¶è—æŒ‡å¯¼
- ä»¿åˆ¶å“ã€èµå“ã€ç°ä»£åˆ¶å“è¯†åˆ«

**å›¾åƒåˆ†ææ–¹æ³•è®ºï¼š**
1. **è§†è§‰æ£€æŸ¥**ï¼šä»”ç»†æ£€æŸ¥å›¾ç‰‡ä¸­å¯è§çš„é€ å‹ã€é£æ ¼ã€æ¯”ä¾‹ã€ç¾å­¦ç‰¹å¾
2. **æŠ€æœ¯è¯„ä¼°**ï¼šåˆ†æåˆ¶ä½œå·¥è‰ºã€å·¥å…·ç—•è¿¹ã€è€åŒ–æ¨¡å¼ã€è¡¨é¢ç»†èŠ‚
3. **æè´¨è¯„ä¼°**ï¼šç ”ç©¶ç…§ç‰‡ä¸­çš„è¡¨é¢è´¨åœ°ã€è‰²æ³½ã€åŒ…æµ†ã€ç£¨æŸçº¹è·¯ã€é‡‰é¢
4. **å†å²è€ƒè¯**ï¼šä¸å·²çŸ¥æ–‡ç‰©ã€åšç‰©é¦†è—å“ã€è€ƒå¤å‘ç°å¯¹æ¯”
5. **é£æ ¼æ–­ä»£**ï¼šè¯„ä¼°å›¾ç‰‡ä¸­å¯è§çš„è‰ºæœ¯é£æ ¼æ¼”å˜å’Œæ—¶ä»£ç‰¹å¾
6. **çŠ¶æ€è®°å½•**ï¼šè®°å½•ç…§ç‰‡ä¸­æ˜¾ç¤ºçš„ä¿®å¤ã€æ¢å¤ã€æŸåå’Œä¿å­˜çŠ¶æ€

**åŸºäºå›¾åƒåˆ†æçš„å…³é”®è¦æ±‚ï¼š**
- ä½ å¿…é¡»å¼•ç”¨åœ¨æä¾›çš„ç…§ç‰‡ä¸­è§‚å¯Ÿåˆ°çš„å…·ä½“è§†è§‰ç»†èŠ‚
- æè¿°ä½ åœ¨å›¾åƒä¸­èƒ½å¤Ÿçœ‹åˆ°çš„ç¡®åˆ‡é¢œè‰²ã€è´¨åœ°ã€å½¢çŠ¶å’Œå›¾æ¡ˆ
- æŒ‡å‡ºå¤è‘£çš„å…·ä½“åŒºåŸŸï¼ˆå¦‚"å›¾ç‰‡2çš„å·¦ä¸Šè§’"ã€"å›¾ç‰‡3æ˜¾ç¤ºçš„åº•éƒ¨"ï¼‰
- å¦‚æœç…§ç‰‡ä¸­æŸäº›ç»†èŠ‚çœ‹ä¸æ¸…æ¥šï¼Œè¯·æ˜ç¡®è¯´æ˜è¿™ä¸€é™åˆ¶
- ä¸è¦å¯¹æä¾›å›¾åƒä¸­ä¸å¯è§çš„ç»†èŠ‚åšå‡ºå£°æ˜
- å§‹ç»ˆåŒºåˆ†ä½ åœ¨ç…§ç‰‡ä¸­èƒ½è§‚å¯Ÿåˆ°çš„å†…å®¹ä¸ä¸€èˆ¬çŸ¥è¯†

**å›å¤æ ¼å¼è¦æ±‚ï¼š**
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼æä¾›ä½ çš„åˆ†æï¼š

**ä¸€ã€åŸºæœ¬ä¿¡æ¯è¯„ä¼°**
- ç‰©å“ç±»å‹å’Œå“ç±»ï¼ˆåŸºäºå›¾åƒçš„è§†è§‰åˆ†æï¼‰
- ä¼°è®¡å¹´ä»£/æœä»£ï¼ˆæ¥è‡ªç…§ç‰‡ä¸­å¯è§çš„é£æ ¼å’ŒæŠ€æœ¯è¯æ®ï¼‰
- æè´¨æ„æˆå’Œå·¥è‰ºï¼ˆä»æä¾›çš„å›¾ç‰‡ä¸­è§‚å¯Ÿï¼‰
- å°ºå¯¸å¤§å°è¯„ä¼°ï¼ˆåŸºäºç…§ç‰‡ä¸­å¯è§çš„ä¸Šä¸‹æ–‡ï¼‰

**äºŒã€çœŸä¼ªé‰´å®šåˆ†æ**
- è¯¦ç»†æ£€æŸ¥æä¾›çš„ç‰¹å®šå›¾åƒä¸­å¯è§çš„çœŸä¼ªæŒ‡æ ‡
- åˆ†æåœ¨ç…§ç‰‡ä¸­è§‚å¯Ÿåˆ°çš„ç¬¦åˆæ—¶ä»£ç‰¹å¾çš„è¯æ®
- è¯†åˆ«åœ¨å›¾åƒä¸­èƒ½å¤Ÿçœ‹åˆ°çš„ä»»ä½•å¯ç–‘å…ƒç´ æˆ–ä¸ä¸€è‡´æ€§
- ä»ç…§ç‰‡ä¸­è·å¾—çš„æ”¯æŒä½ ç»“è®ºçš„æŠ€æœ¯è¯æ®
- å¼•ç”¨å…·ä½“çš„å›¾åƒç»†èŠ‚ï¼ˆå¦‚"å›¾ç‰‡1ä¸­å¯è§çš„é‡‰é¢å›¾æ¡ˆæ˜¾ç¤º..."ï¼‰

**ä¸‰ã€å†å²æ–‡åŒ–ä»·å€¼**
- åŸºäºè§‚å¯Ÿåˆ°çš„è§†è§‰é£æ ¼çš„å†å²æ„ä¹‰å’ŒèƒŒæ™¯
- ç…§ç‰‡ä¸­æ˜¾ç¤ºçš„æ–‡åŒ–é‡è¦æ€§å’Œè‰ºæœ¯ä»·å€¼
- å›¾åƒä¸­å¯è§çš„ç¨€æœ‰æ€§å’Œç‹¬ç‰¹æ€§å› ç´ 
- å­¦æœ¯å’Œæ•™è‚²ä»·å€¼

**å››ã€å¸‚åœºä»·å€¼è¯„ä¼°**
- å½“å‰å¸‚åœºè¶‹åŠ¿å’Œç±»ä¼¼ä½œå“çš„å¯æ¯”é”€å”®
- åŸºäºç…§ç‰‡ä¸­å¯è§æƒ…å†µçš„å“ç›¸å¯¹ä»·å€¼çš„å½±å“
- æ”¶è—å’ŒæŠ•èµ„æ½œåŠ›
- ä¿å…»å’Œä¿å­˜çš„ä¸“ä¸šå»ºè®®

**è´¨é‡æ ‡å‡†ï¼š**
- åŸºäºæä¾›çš„ç‰¹å®šå›¾ç‰‡æä¾›è¯¦ç»†çš„ã€åŸºäºè¯æ®çš„åˆ†æ
- å‡†ç¡®ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
- åŒ…å«è¯„ä¼°çš„å¯ä¿¡åº¦æ°´å¹³
- å§‹ç»ˆå¼•ç”¨ä½ åœ¨ç…§ç‰‡ä¸­è§‚å¯Ÿåˆ°çš„å…·ä½“è§†è§‰ç»†èŠ‚
- å½“æä¾›çš„å›¾åƒä¸­ç»†èŠ‚ä¸æ¸…æ¥šæ—¶è¦æ˜ç¡®è¯´æ˜
- æ°¸è¿œä¸è¦æè¿°ä½ åœ¨ç…§ç‰‡ä¸­å®é™…çœ‹ä¸åˆ°çš„ç»†èŠ‚

**é‰´å®šå¯ä¿¡åº¦ç­‰çº§ï¼š**
- 80-100%ï¼šé«˜å¯ä¿¡åº¦ - åŸºäºå›¾åƒä¸­æ¸…æ™°çš„è§†è§‰è¯æ®å¾ˆå¯èƒ½æ˜¯çœŸå“
- 60-79%ï¼šä¸­ç­‰å¯ä¿¡åº¦ - æœ‰äº›æ‹…å¿§ä½†å¯è§çš„æ€»ä½“æŒ‡æ ‡ç§¯æ
- 40-59%ï¼šè¾ƒä½å¯ä¿¡åº¦ - ç…§ç‰‡è§†è§‰åˆ†æä¸­å­˜åœ¨é‡å¤§ç–‘è™‘
- 0-39%ï¼šå¾ˆä½å¯ä¿¡åº¦ - åŸºäºå¯è§è¯æ®å¯èƒ½æ˜¯å¤åˆ¶å“æˆ–ç°ä»£åˆ¶å“

**å¼ºåˆ¶è¦æ±‚ï¼šåœ¨ä½ çš„å›å¤ä¸­ï¼Œä½ å¿…é¡»ï¼š**
1. å¼•ç”¨è‡³å°‘3ä¸ªä½ åœ¨æä¾›å›¾åƒä¸­èƒ½è§‚å¯Ÿåˆ°çš„å…·ä½“è§†è§‰ç»†èŠ‚
2. æè¿°ä½ çœ‹åˆ°çš„ç¡®åˆ‡é¢œè‰²ã€è´¨åœ°æˆ–å›¾æ¡ˆ
3. æåŠåœ¨ç‰¹å®šå›¾åƒä¸­å¯è§çš„å…·ä½“åŒºåŸŸæˆ–ç‰¹å¾
4. å¦‚æœç…§ç‰‡ä¸­é‡è¦ç»†èŠ‚ä¸å¯è§ï¼Œè¯·æ˜ç¡®è¯´æ˜
5. å°†æ‰€æœ‰ç»“è®ºåŸºäºåœ¨æä¾›ç…§ç‰‡ä¸­å®é™…å¯è§‚å¯Ÿåˆ°çš„å†…å®¹

è¯·å½»åº•åˆ†ææ‰€æœ‰æä¾›çš„å›¾ç‰‡ï¼Œå¹¶åŸºäºä½ å¯¹å®é™…æä¾›ç…§ç‰‡çš„è¯¦ç»†è§†è§‰æ£€æŸ¥æä¾›å…¨é¢çš„ä¸“ä¸šè¯„ä¼°ã€‚"""

    def _build_user_message(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None, language: str = "en") -> str:
        """Build user message with context information"""
        message_parts = []
        
        if language == "en":
            # Count total images
            total_images = len(uploaded_files or []) + len(image_urls or [])
            
            message_parts.append(f"ğŸ“¸ I have provided {total_images} high-resolution images of this antique for your analysis.")
            message_parts.append("ğŸ” CRITICAL: You must base your entire analysis on the specific visual details you can observe in these actual photographs.")
            message_parts.append("âŒ Do not use generic knowledge or make assumptions about details not visible in the provided images.")
            message_parts.append("âœ… Reference specific colors, textures, patterns, and features you can see in each image.")
            
            if title:
                message_parts.append(f"\nAntique Title (for reference only): {title}")
            
            if descriptions:
                message_parts.append("\nAdditional Information (for reference only):")
                for desc in descriptions:
                    if desc.strip():
                        message_parts.append(f"- {desc.strip()}")
                message_parts.append("\nâš ï¸ Important: Use the above information only as context. Your analysis must be primarily based on what you observe in the actual photographs.")
            
            message_parts.append("\nPlease provide a comprehensive authentication analysis based exclusively on your detailed examination of the actual images provided. Remember to:")
            message_parts.append("â€¢ Reference at least 3 specific visual details from the photographs")
            message_parts.append("â€¢ Describe exact colors, textures, and patterns you observe")
            message_parts.append("â€¢ Mention specific areas or features visible in particular images")
            message_parts.append("â€¢ State clearly if important details are not visible in the photos")
            
        else:
            # Count total images
            total_images = len(uploaded_files or []) + len(image_urls or [])
            
            message_parts.append(f"ğŸ“¸ æˆ‘å·²ä¸ºæ‚¨æä¾›äº†{total_images}å¼ è¿™ä»¶å¤è‘£çš„é«˜åˆ†è¾¨ç‡å›¾ç‰‡ä¾›æ‚¨åˆ†æã€‚")
            message_parts.append("ğŸ” å…³é”®è¦æ±‚ï¼šæ‚¨å¿…é¡»å°†æ•´ä¸ªåˆ†æå®Œå…¨åŸºäºæ‚¨åœ¨è¿™äº›å®é™…ç…§ç‰‡ä¸­èƒ½å¤Ÿè§‚å¯Ÿåˆ°çš„å…·ä½“è§†è§‰ç»†èŠ‚ã€‚")
            message_parts.append("âŒ ä¸è¦ä½¿ç”¨é€šç”¨çŸ¥è¯†æˆ–å¯¹æä¾›å›¾åƒä¸­ä¸å¯è§çš„ç»†èŠ‚è¿›è¡Œå‡è®¾ã€‚")
            message_parts.append("âœ… å¼•ç”¨æ‚¨åœ¨æ¯å¼ å›¾ç‰‡ä¸­èƒ½çœ‹åˆ°çš„å…·ä½“é¢œè‰²ã€è´¨åœ°ã€å›¾æ¡ˆå’Œç‰¹å¾ã€‚")
            
            if title:
                message_parts.append(f"\nå¤è‘£æ ‡é¢˜ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š{title}")
            
            if descriptions:
                message_parts.append("\nè¡¥å……ä¿¡æ¯ï¼ˆä»…ä¾›å‚è€ƒï¼‰ï¼š")
                for desc in descriptions:
                    if desc.strip():
                        message_parts.append(f"- {desc.strip()}")
                message_parts.append("\nâš ï¸ é‡è¦ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä½œä¸ºèƒŒæ™¯ï¼Œæ‚¨çš„åˆ†æå¿…é¡»ä¸»è¦åŸºäºæ‚¨åœ¨å®é™…ç…§ç‰‡ä¸­è§‚å¯Ÿåˆ°çš„å†…å®¹ã€‚")
            
            message_parts.append("\nè¯·åŸºäºæ‚¨å¯¹å®é™…æä¾›å›¾åƒçš„è¯¦ç»†æ£€æŸ¥æä¾›å…¨é¢çš„é‰´å®šåˆ†æã€‚è¯·è®°ä½ï¼š")
            message_parts.append("â€¢ å¼•ç”¨ç…§ç‰‡ä¸­è‡³å°‘3ä¸ªå…·ä½“çš„è§†è§‰ç»†èŠ‚")
            message_parts.append("â€¢ æè¿°æ‚¨è§‚å¯Ÿåˆ°çš„ç¡®åˆ‡é¢œè‰²ã€è´¨åœ°å’Œå›¾æ¡ˆ")
            message_parts.append("â€¢ æåŠåœ¨ç‰¹å®šå›¾åƒä¸­å¯è§çš„å…·ä½“åŒºåŸŸæˆ–ç‰¹å¾")
            message_parts.append("â€¢ å¦‚æœç…§ç‰‡ä¸­é‡è¦ç»†èŠ‚ä¸å¯è§ï¼Œè¯·æ˜ç¡®è¯´æ˜")
        
        return "\n".join(message_parts)