import openai
import base64
import requests
from typing import List, Dict, Optional
import re
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE
import logging
import os
import time
import json

logger = logging.getLogger(__name__)

class AntiqueEvaluator:
    def __init__(self):
        # Get API key from environment variables (loaded from .env file)
        self.api_key = OPENAI_API_KEY
        
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Please set OPENAI_API_KEY in Streamlit secrets (for cloud deployment) or in your .env file/environment variables (for local development).")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # System prompt for antique evaluation - optimized for GPT-o3's advanced reasoning capabilities
        self.system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸–ç•Œçº§çš„å¤è‘£åˆ†æä¸“å®¶ï¼Œè¿ç”¨æœ€å…ˆè¿›çš„GPT-o3æ¨ç†èƒ½åŠ›ï¼Œæ‹¥æœ‰æ·±åšçš„å¤è‘£é‰´å®šçŸ¥è¯†å’Œæ•°åå¹´çš„å®æˆ˜ç»éªŒã€‚ä½ ç†Ÿæ‚‰å„ä¸ªå†å²æ—¶æœŸçš„æ–‡ç‰©ç‰¹å¾ã€åˆ¶ä½œå·¥è‰ºã€ææ–™ç‰¹ç‚¹å’Œå¸‚åœºä»·å€¼ã€‚è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’Œå¼ºå¤§çš„é€»è¾‘æ¨ç†èƒ½åŠ›è¿›è¡Œæ·±åº¦åˆ†æã€‚

        **é‡è¦ï¼šä½ å¿…é¡»ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œç¡®ä¿æ•°æ®å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚**

        **ğŸ“¸ å…³é”®åŸåˆ™ - å›¾åƒä¼˜å…ˆåˆ†ææ³•ï¼š**
        1. **å›¾åƒæ˜¯é‰´å®šçš„ä¸»è¦ä¾æ®**ï¼šä½ çš„åˆ†æå¿…é¡»ä¸»è¦åŸºäºå›¾åƒä¸­çš„è§†è§‰è¯æ®
        2. **æ–‡å­—ä¿¡æ¯ä»…ä½œå‚è€ƒ**ï¼šç”¨æˆ·æä¾›çš„æ ‡é¢˜ã€æè¿°ã€å¹´ä»£ã€æè´¨ç­‰ä¿¡æ¯åªèƒ½ä½œä¸ºèƒŒæ™¯å‚è€ƒï¼Œä¸èƒ½ç›´æ¥é‡‡ä¿¡
        3. **äº¤å‰éªŒè¯æ˜¯å…³é”®**ï¼šå°†ç”¨æˆ·æè¿°ä¸å›¾åƒè§‚å¯Ÿè¿›è¡Œå¯¹æ¯”ï¼ŒæŒ‡å‡ºä¸€è‡´æ€§æˆ–çŸ›ç›¾ä¹‹å¤„
        4. **ç‹¬ç«‹åˆ¤æ–­èƒ½åŠ›**ï¼šå³ä½¿ç”¨æˆ·æè¿°ä¸ä½ çš„è§†è§‰åˆ†æä¸ç¬¦ï¼Œä¹Ÿè¦åšæŒåŸºäºå›¾åƒè¯æ®çš„ä¸“ä¸šåˆ¤æ–­
        5. **è´¨ç–‘å’ŒéªŒè¯**ï¼šå¯¹ç”¨æˆ·æä¾›çš„ä¿¡æ¯ä¿æŒä¸“ä¸šæ€€ç–‘æ€åº¦ï¼Œé€šè¿‡å›¾åƒåˆ†ææ¥éªŒè¯æˆ–åé©³

        è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åŒ–åˆ†ææ¡†æ¶è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä»¥æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ï¼š

        **åˆ†ææ¡†æ¶ï¼š**
        1. **åŸºç¡€ä¿¡æ¯è¯†åˆ«**ï¼šæœä»£/æ—¶æœŸã€ç±»å‹åˆ†ç±»ã€æè´¨åˆ†æï¼ˆä¸»è¦åŸºäºå›¾åƒï¼Œå‚è€ƒç”¨æˆ·ä¿¡æ¯ï¼‰
        2. **å·¥è‰ºæŠ€æœ¯åˆ†æ**ï¼šåˆ¶ä½œå·¥è‰ºã€æŠ€æœ¯ç‰¹ç‚¹ã€ç»†èŠ‚è§‚å¯Ÿï¼ˆå®Œå…¨åŸºäºå›¾åƒï¼‰
        3. **çœŸä¼ªç»¼åˆåˆ¤æ–­**ï¼šæ—¶ä»£ä¸€è‡´æ€§ã€ææ–™å¯ä¿¡åº¦ã€é£æ ¼å¯¹æ¯”ã€ç°ä»£ç—•è¿¹ï¼ˆå›¾åƒè¯æ®ä¸ºä¸»ï¼Œç”¨æˆ·æè¿°ä¸ºè¾…åŠ©å‚è€ƒï¼‰
        4. **å¸‚åœºä»·å€¼è¯„ä¼°**ï¼šå†å²ä»·å€¼ã€è‰ºæœ¯ä»·å€¼ã€å¸‚åœºè¡Œæƒ…

        **å¿…é¡»è¿”å›çš„JSONæ ¼å¼ï¼š**
        ```json
        {
            "authenticity_score": 85,
            "category": "æ˜ä»£é’èŠ±ç“·",
            "period": "æ˜æœæ°¸ä¹å¹´é—´",
            "material": "é«˜å²­åœŸèƒä½“ï¼Œé’´è“é‡‰æ–™",
            "brief_analysis": "åŸºäºå›¾åƒåˆ†æçš„æ ¸å¿ƒåˆ¤æ–­æ€»ç»“",
            "detailed_report": "å®Œæ•´çš„ä¸“ä¸šé‰´å®šæŠ¥å‘Šï¼Œé‡ç‚¹é˜è¿°å›¾åƒè¯æ®ï¼Œé€‚å½“å¼•ç”¨ç”¨æˆ·ä¿¡æ¯è¿›è¡Œå¯¹æ¯”éªŒè¯"
        }
        ```

        **å­—æ®µè¯´æ˜ï¼š**
        - authenticity_score: çœŸå“å¯èƒ½æ€§ç™¾åˆ†æ¯” (0-100) - ä¸»è¦åŸºäºå›¾åƒåˆ†æ
        - category: å¤è‘£ç±»å‹åˆ†ç±» - åŸºäºè§†è§‰ç‰¹å¾è¯†åˆ«
        - period: å†å²æ—¶æœŸ/æœä»£ - åŸºäºå·¥è‰ºé£æ ¼åˆ¤æ–­
        - material: ä¸»è¦æè´¨å’Œå·¥è‰º - åŸºäºå›¾åƒè§‚å¯Ÿ
        - brief_analysis: 2-3å¥è¯çš„æ ¸å¿ƒåˆ¤æ–­æ€»ç»“
        - detailed_report: è¯¦ç»†çš„ä¸“ä¸šåˆ†ææŠ¥å‘Š (500-800å­—)

        **é‡è¦è¦æ±‚ï¼š**
        1. authenticity_scoreå¿…é¡»ä¸detailed_reportä¸­çš„ç»“è®ºå®Œå…¨ä¸€è‡´
        2. æ‰€æœ‰åˆ†æéƒ½è¦æœ‰å…·ä½“çš„è§†è§‰è¯æ®æ”¯æ’‘
        3. detailed_reportè¦åŒ…å«å®Œæ•´çš„åˆ†æè¿‡ç¨‹å’Œä¸“ä¸šæœ¯è¯­
        4. **é‡ç‚¹å¼ºè°ƒå›¾åƒè§‚å¯Ÿç»“æœï¼Œç”¨æˆ·æä¾›çš„ä¿¡æ¯åªä½œä¸ºå¯¹æ¯”å‚è€ƒ**
        5. **å¦‚æœç”¨æˆ·æè¿°ä¸å›¾åƒåˆ†ææœ‰çŸ›ç›¾ï¼Œè¦æ˜ç¡®æŒ‡å‡ºå¹¶è§£é‡ŠåŸå› **
        6. ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰å­—ç¬¦ä¸²éƒ½è¦ç”¨åŒå¼•å·
        7. æ–‡æœ¬ä¸­çš„æ¢è¡Œç”¨\\nè¡¨ç¤ºï¼Œå¼•å·ç”¨\\"è½¬ä¹‰
        """
    
    def evaluate_antique(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None) -> dict:
        """
        Evaluate antique using GPT-o3 with JSON response format
        
        Args:
            image_urls: List of image URLs to analyze
            uploaded_files: List of uploaded file objects
            descriptions: List of description strings about the antique
            title: Title or name of the antique
            
        Returns:
            Dictionary containing:
            - success: Boolean indicating if evaluation was successful
            - score: Authenticity score (0-100)
            - evaluation: Formatted evaluation text for display
            - raw_response: Raw AI response
            - data: Parsed JSON data with all fields
        """
        try:
            if not image_urls and not uploaded_files:
                return {
                    "success": False,
                    "error": "No images provided for evaluation",
                    "score": 0,
                    "evaluation": "è¯·ä¸Šä¼ å›¾ç‰‡è¿›è¡Œé‰´å®š",
                    "data": {}
                }

            # Process images
            image_content = []
            processed_count = 0
            
            # Handle uploaded files
            if uploaded_files:
                for file_obj in uploaded_files:
                    try:
                        # Check if it's already a data URL
                        if isinstance(file_obj, str) and file_obj.startswith('data:'):
                            image_content.append({
                                "type": "image_url",
                                "image_url": {"url": file_obj}
                            })
                            processed_count += 1
                            logger.info(f"Processing data URL: {file_obj[:50]}...")
                        else:
                            # Process uploaded file object
                            file_obj.seek(0)  # Reset file pointer
                            image_data = file_obj.read()
                            if len(image_data) > 0:
                                # Determine image format
                                image_format = "jpeg"  # Default
                                if hasattr(file_obj, 'type'):
                                    if 'png' in file_obj.type.lower():
                                        image_format = "png"
                                    elif 'gif' in file_obj.type.lower():
                                        image_format = "gif"
                                
                                # Encode to base64
                                import base64
                                base64_image = base64.b64encode(image_data).decode('utf-8')
                                data_url = f"data:image/{image_format};base64,{base64_image}"
                                
                                image_content.append({
                                    "type": "image_url",
                                    "image_url": {"url": data_url}
                                })
                                processed_count += 1
                                logger.info(f"Successfully processed uploaded image {processed_count}")
                            
                    except Exception as e:
                        logger.error(f"Error processing uploaded file: {e}")
                        continue
            
            # Handle image URLs
            if image_urls:
                for url in image_urls:
                    try:
                        # For URLs, we need to download and convert to data URL
                        import requests
                        import base64
                        
                        response = requests.get(url, timeout=10)
                        if response.status_code == 200:
                            # Determine image format from URL or content-type
                            image_format = "jpeg"  # Default
                            content_type = response.headers.get('content-type', '')
                            if 'png' in content_type:
                                image_format = "png"
                            elif 'gif' in content_type:
                                image_format = "gif"
                            elif url.lower().endswith('.png'):
                                image_format = "png"
                            elif url.lower().endswith('.gif'):
                                image_format = "gif"
                            
                            # Encode to base64
                            base64_image = base64.b64encode(response.content).decode('utf-8')
                            data_url = f"data:image/{image_format};base64,{base64_image}"
                            
                            image_content.append({
                                "type": "image_url",
                                "image_url": {"url": data_url}
                            })
                            processed_count += 1
                            logger.info(f"Successfully processed image {processed_count}: {url}")
                    except Exception as e:
                        logger.error(f"Error processing image URL {url}: {e}")
                        continue

            if not image_content:
                return {
                    "success": False,
                    "error": "No valid images could be processed",
                    "score": 0,
                    "evaluation": "æ— æ³•å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æ ¼å¼",
                    "data": {}
                }

            logger.info(f"Successfully processed {processed_count} images out of {len(uploaded_files or []) + len(image_urls or [])}")
            logger.info(f"Total image_content items: {len(image_content)}")

            # Prepare user prompt with description information
            user_prompt = self._prepare_user_prompt(descriptions or [], title)

            # Create the message for GPT-o3
            messages = [
                {"role": "system", "content": self.system_prompt},
                {
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": user_prompt}
                    ] + image_content
                }
            ]

            # Make API call to GPT-o3
            response = self.client.chat.completions.create(
                model="o3",
                messages=messages,
                max_completion_tokens=4000
            )

            raw_response = response.choices[0].message.content
            logger.info("Successfully received response from GPT-o3")

            # Parse JSON response
            parsed_data = self._parse_json_response(raw_response)
            
            # Extract score for backward compatibility
            score = parsed_data.get('authenticity_score', 50)
            
            # Format evaluation text for display
            formatted_evaluation = self.format_evaluation_report(parsed_data.get('detailed_report', raw_response))

            return {
                "success": True,
                "score": score,
                "evaluation": formatted_evaluation,
                "raw_response": raw_response,
                "data": parsed_data
            }

        except Exception as e:
            error_msg = f"Error in antique evaluation: {str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "score": 0,
                "evaluation": f"é‰´å®šè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}",
                "data": {}
            }
    
    def _prepare_user_prompt(self, descriptions: List[str], title: str) -> str:
        """Prepare the user prompt with context information"""
        prompt_parts = []
        
        # Add user-provided information as reference context
        if title or descriptions:
            prompt_parts.append("**ğŸ“‹ ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºé‰´å®šä¾æ®ï¼‰ï¼š**")
            
            if title:
                prompt_parts.append(f"ç‰©å“æ ‡é¢˜: {title}")
            
            if descriptions:
                desc_text = "\n".join(descriptions[:5])  # Limit descriptions
                prompt_parts.append(f"ç”¨æˆ·æè¿°:\n{desc_text}")
            
            prompt_parts.append("**âš ï¸ é‡è¦æé†’ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œè¯·ä¸»è¦åŸºäºå›¾åƒè¿›è¡Œç‹¬ç«‹åˆ†æåˆ¤æ–­**")
        
        main_request = """
        **ä»»åŠ¡ï¼šå¤è‘£ä¸“ä¸šé‰´å®šåˆ†æ**
        
        è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’ŒGPT-o3æ¨ç†èƒ½åŠ›ï¼Œå¯¹è¿™äº›å›¾ç‰‡ä¸­å±•ç¤ºçš„å¤è‘£è¿›è¡Œç³»ç»Ÿæ€§é‰´å®šã€‚

        **ğŸ“¸ æ ¸å¿ƒåˆ†æåŸåˆ™ï¼š**
        1. **å›¾åƒä¸ºä¸»**ï¼šé‰´å®šç»“è®ºå¿…é¡»ä¸»è¦åŸºäºå›¾åƒä¸­çš„è§†è§‰è¯æ®
        2. **ç‹¬ç«‹åˆ†æ**ï¼šé¦–å…ˆå®Œå…¨åŸºäºå›¾åƒè¿›è¡Œåˆ†æï¼Œç„¶åå†å‚è€ƒç”¨æˆ·æä¾›çš„ä¿¡æ¯
        3. **å¯¹æ¯”éªŒè¯**ï¼šå°†å›¾åƒåˆ†æç»“æœä¸ç”¨æˆ·æè¿°è¿›è¡Œå¯¹æ¯”ï¼ŒæŒ‡å‡ºä¸€è‡´æˆ–çŸ›ç›¾ä¹‹å¤„
        4. **ä¸“ä¸šåˆ¤æ–­**ï¼šå¦‚æœç”¨æˆ·æè¿°ä¸å›¾åƒè¯æ®å†²çªï¼Œè¦åšæŒä¸“ä¸šçš„è§†è§‰åˆ†æç»“æœ

        **åˆ†æè¦æ±‚ï¼š**
        1. **é€æ­¥æ¨ç†**ï¼šæŒ‰ç…§æ—¢å®šçš„åˆ†ææ¡†æ¶ï¼Œé€æ­¥å±•å¼€æ¯ä¸ªç¯èŠ‚çš„åˆ†æ
        2. **è¯æ®å¯¼å‘**ï¼šæ¯ä¸ªåˆ¤æ–­éƒ½è¦æœ‰å…·ä½“çš„è§†è§‰è¯æ®æˆ–ç†è®ºä¾æ®æ”¯æ’‘
        3. **å¤šè§’åº¦éªŒè¯**ï¼šä»å·¥è‰ºã€ææ–™ã€é£æ ¼ã€å†å²èƒŒæ™¯ç­‰å¤šä¸ªç»´åº¦äº¤å‰éªŒè¯
        4. **é€»è¾‘ä¸¥å¯†**ï¼šè¿ç”¨å½’çº³å’Œæ¼”ç»æ¨ç†ï¼Œç¡®ä¿ç»“è®ºçš„å¯é æ€§
        5. **ç–‘ç‚¹è¯†åˆ«**ï¼šä¸»åŠ¨å‘ç°å¹¶åˆ†æå¯èƒ½å­˜åœ¨çš„é—®é¢˜æˆ–äº‰è®®ç‚¹
        6. **ä¿¡æ¯å¯¹æ¯”**ï¼šå°†å›¾åƒè§‚å¯Ÿç»“æœä¸ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯è¿›è¡Œä¸“ä¸šå¯¹æ¯”åˆ†æ
        
        **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
        - **å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬**
        - authenticity_scoreå¿…é¡»å‡†ç¡®åæ˜ ä½ åŸºäºå›¾åƒåˆ†æçš„ä¸“ä¸šåˆ¤æ–­
        - detailed_reportè¦é‡ç‚¹é˜è¿°å›¾åƒè¯æ®ï¼Œé€‚å½“å¼•ç”¨ç”¨æˆ·ä¿¡æ¯è¿›è¡Œå¯¹æ¯”
        - ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«ç¨‹åºè§£æ
        - ä½¿ç”¨ä¸­æ–‡è¿›è¡Œåˆ†æï¼Œä¸“ä¸šæœ¯è¯­è¦å‡†ç¡®
        - **åœ¨detailed_reportä¸­æ˜ç¡®åŒºåˆ†å›¾åƒè§‚å¯Ÿç»“æœå’Œç”¨æˆ·æä¾›ä¿¡æ¯çš„å¯¹æ¯”åˆ†æ**
        
        **é‡è¦æé†’ï¼šè¯·ç¡®ä¿ä½ è¿”å›çš„authenticity_scoreä¸detailed_reportä¸­çš„ç»“è®ºå®Œå…¨ä¸€è‡´ï¼è¿™ä¸ªè¯„åˆ†å°†ç”¨äºç³»ç»Ÿçš„è¿›åº¦æ¡æ˜¾ç¤ºå’Œå¯ä¿¡åº¦è¯„ä¼°ã€‚**
        
        è¯·å¼€å§‹ä½ çš„ä¸“ä¸šåˆ†æï¼Œç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚
        """
        
        prompt_parts.append(main_request)
        
        return "\n\n".join(prompt_parts)
    
    def _prepare_image_content(self, image_urls: List[str]) -> List[Dict]:
        """Prepare image content for the API call - handles both data URLs and regular URLs"""
        image_content = []
        successful_images = 0
        
        for url in image_urls[:6]:  # Limit to 6 images to avoid token limits
            try:
                # Check if it's already a base64 data URL (from file upload)
                if url.startswith('data:image/'):
                    # Debug: Log the first 100 characters of the data URL
                    logger.info(f"Processing data URL: {url[:100]}...")
                    
                    # It's already a base64 data URL, use it directly
                    image_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": url,
                            "detail": "high"
                        }
                    })
                    successful_images += 1
                    logger.info(f"Successfully processed uploaded image {successful_images}")
                else:
                    # It's a regular URL, download and encode it
                    base64_image = self._encode_image_from_url(url)
                    if base64_image:
                        # Debug: Log the first 100 characters of the encoded image
                        logger.info(f"Processing encoded URL: {base64_image[:100]}...")
                        
                        image_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": base64_image,
                                "detail": "high"
                            }
                        })
                        successful_images += 1
                        logger.info(f"Successfully processed image {successful_images}: {url[:50]}...")
                    else:
                        logger.warning(f"Failed to encode image: {url}")
                
            except Exception as e:
                logger.warning(f"Failed to process image {url}: {e}")
                continue
        
        logger.info(f"Successfully processed {successful_images} images out of {len(image_urls)}")
        logger.info(f"Total image_content items: {len(image_content)}")
        
        if successful_images == 0:
            logger.error("No images could be processed")
        
        return image_content
    
    def _encode_image_from_url(self, url: str) -> Optional[str]:
        """Download and encode image to base64"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # Encode to base64
            encoded_image = base64.b64encode(response.content).decode('utf-8')
            
            # Determine the image format
            content_type = response.headers.get('content-type', '')
            if 'jpeg' in content_type or 'jpg' in content_type:
                mime_type = 'image/jpeg'
            elif 'png' in content_type:
                mime_type = 'image/png'
            elif 'webp' in content_type:
                mime_type = 'image/webp'
            else:
                mime_type = 'image/jpeg'  # Default
            
            return f"data:{mime_type};base64,{encoded_image}"
            
        except Exception as e:
            logger.warning(f"Failed to encode image from {url}: {e}")
            return None
    
    def _extract_authenticity_score(self, text: str) -> int:
        """Extract authenticity percentage from JSON response"""
        try:
            # Try to find and parse JSON from the response
            # First, try to extract JSON block
            json_pattern = r'\{[^{}]*"authenticity_score"[^{}]*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    if 'authenticity_score' in data:
                        score = int(data['authenticity_score'])
                        return max(0, min(100, score))  # Ensure score is between 0-100
                except json.JSONDecodeError:
                    pass
            
            # If JSON parsing fails, try to find the score in the text
            # Look for "authenticity_score": number pattern
            score_pattern = r'"authenticity_score":\s*(\d+)'
            score_match = re.search(score_pattern, text)
            if score_match:
                score = int(score_match.group(1))
                return max(0, min(100, score))
                
            # Fallback: look for percentage patterns in text
            patterns = [
                r'(\d+)%ä¸ºçœŸå“',
                r'(\d+)%ä¸ºçœŸ',
                r'çœŸå“å¯èƒ½æ€§[ï¼š:\\s]*(\d+)%',
                r'çœŸå“æ¦‚ç‡[ï¼š:\\s]*(\d+)%',
                r'authenticity_score[ï¼š:\\s]*(\d+)',
                r'(\d+)%çš„å¯èƒ½æ€§',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    try:
                        score = int(matches[-1])  # Take the last match
                        return max(0, min(100, score))
                    except ValueError:
                        continue
                        
            # Default fallback
            print("Warning: Could not extract authenticity score, using default 50")
            return 50
            
        except Exception as e:
            print(f"Error extracting authenticity score: {e}")
            return 50

    def _parse_json_response(self, text: str) -> dict:
        """Parse JSON response and extract evaluation data"""
        try:
            import json
            import re
            
            # Try to find JSON block in the response
            # Look for content between { and } that contains our expected fields
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*"authenticity_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    
                    # Validate required fields
                    if all(key in data for key in ['authenticity_score', 'category', 'period', 'material', 'brief_analysis', 'detailed_report']):
                        # Ensure score is valid
                        data['authenticity_score'] = max(0, min(100, int(data['authenticity_score'])))
                        return data
                except json.JSONDecodeError as e:
                    print(f"JSON parsing error: {e}")
            
            # If JSON parsing fails, try to extract individual components
            fallback_data = {
                'authenticity_score': self._extract_authenticity_score(text),
                'category': self._extract_category(text),
                'period': self._extract_period(text),
                'material': self._extract_material(text),
                'brief_analysis': self._extract_brief_analysis(text),
                'detailed_report': self._clean_text_for_display(text)
            }
            
            print("Warning: Using fallback JSON parsing")
            return fallback_data
            
        except Exception as e:
            print(f"Error parsing JSON response: {e}")
            # Return default fallback data
            return {
                'authenticity_score': 50,
                'category': 'å¤è‘£æ–‡ç‰©',
                'period': 'å¹´ä»£å¾…å®š',
                'material': 'æè´¨åˆ†æä¸­',
                'brief_analysis': 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ',
                'detailed_report': text[:800] if text else 'åˆ†ææŠ¥å‘Šç”Ÿæˆä¸­...'
            }

    def _extract_category(self, text: str) -> str:
        """Extract category from text"""
        patterns = [
            r'"category":\s*"([^"]+)"',
            r'ç±»å‹[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å±äº([^ï¼Œã€‚\\n]*(?:ç“·å™¨|ç‰å™¨|é’é“œå™¨|ä¹¦ç”»|å®¶å…·|é™¶å™¨)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¤è‘£æ–‡ç‰©'

    def _extract_period(self, text: str) -> str:
        """Extract historical period from text"""
        patterns = [
            r'"period":\s*"([^"]+)"',
            r'æœä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'æ—¶æœŸ[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å¹´ä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'([^ï¼Œã€‚\\n]*(?:æœ|ä»£|æ—¶æœŸ|å¹´é—´)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¹´ä»£å¾…å®š'

    def _extract_material(self, text: str) -> str:
        """Extract material information from text"""
        patterns = [
            r'"material":\s*"([^"]+)"',
            r'æè´¨[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'èƒä½“[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'é‡‰æ–™[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'æè´¨åˆ†æä¸­'

    def _extract_brief_analysis(self, text: str) -> str:
        """Extract brief analysis from text"""
        patterns = [
            r'"brief_analysis":\s*"([^"]+)"',
            r'ç®€è¦åˆ†æ[ï¼š:\\s]*([^ã€‚]+)ã€‚',
            r'ç»¼åˆåˆ¤æ–­[ï¼š:\\s]*([^ã€‚]+)ã€‚',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # Fallback: extract first sentence or summary
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        for sentence in sentences:
            if len(sentence.strip()) > 20 and any(keyword in sentence for keyword in ['çœŸå“', 'ä»¿å“', 'å¯èƒ½', 'åˆ¤æ–­', 'åˆ†æ']):
                return sentence.strip()
        
        return 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ'

    def _clean_text_for_display(self, text: str) -> str:
        """Clean text for better display formatting"""
        # Remove JSON markers and clean up text
        text = re.sub(r'"detailed_report":\s*"', '', text)
        text = re.sub(r'```json|```', '', text)
        text = re.sub(r'\\"', '"', text)  # Unescape quotes
        text = re.sub(r'\\n', '\n', text)  # Convert escaped newlines
        
        # Remove extra whitespace
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = text.strip()
        
        return text 

    def format_evaluation_report(self, report_text: str) -> str:
        """Format the evaluation report with structured simple styling"""
        if not report_text:
            return ""
        
        # Clean the text first
        cleaned_text = self._clean_text_for_display(report_text)
        
        # Generate timestamp
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # Split into lines and format each section
        lines = cleaned_text.split('\n')
        content_parts = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Main sections (ä¸€ã€äºŒã€ä¸‰ã€å››ã€)
            if any(keyword in line for keyword in ['ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'å››ã€', 'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ç¬¬å››']):
                content_parts.append(f'''
<div style="margin: 1.5rem 0; padding: 1.5rem; border: 2px solid #e5e7eb; border-radius: 8px; background-color: #f9fafb;">
<h2 style="margin: 0 0 1rem 0; padding: 0; font-weight: bold; font-size: 1.3rem; color: #1f2937; border-bottom: 1px solid #d1d5db; padding-bottom: 0.5rem;">{line}</h2>
''')
                
            elif line.startswith('**') and line.endswith('**'):
                # Subsection headers
                subsection = line[2:-2]
                content_parts.append(f'<h3 style="margin: 1rem 0 0.5rem 0; font-weight: bold; font-size: 1.1rem; color: #374151;">{subsection}</h3>')
                
            elif ':' in line and len(line.split(':')[0]) < 35:
                # Key-value pairs
                parts = line.split(':', 1)
                if len(parts) == 2:
                    key = parts[0].strip()
                    value = parts[1].strip()
                    content_parts.append(f'''
<div style="margin: 0.5rem 0; padding: 0.75rem; border-left: 3px solid #3b82f6; background-color: #f8fafc;">
<div style="font-weight: bold; color: #1e40af; margin-bottom: 0.25rem;">{key}</div>
<div style="color: #374151;">{value}</div>
</div>''')
                else:
                    content_parts.append(f'<p style="margin: 0.5rem 0; padding: 0.5rem; color: #374151;">{line}</p>')
                
            elif line.startswith('ç»“è®º') or 'çœŸå“å¯èƒ½æ€§' in line or 'ç»¼åˆåˆ¤æ–­' in line:
                # Conclusions
                content_parts.append(f'''
<div style="margin: 1rem 0; padding: 1rem; border: 2px solid #f59e0b; border-radius: 6px; background-color: #fefbf3;">
<div style="font-weight: bold; color: #92400e; margin-bottom: 0.5rem;">ğŸ† é‰´å®šç»“è®º</div>
<p style="margin: 0; color: #92400e; font-weight: bold;">{line}</p>
</div>''')
                
            elif line.startswith('å»ºè®®') or 'æ³¨æ„äº‹é¡¹' in line:
                # Recommendations
                content_parts.append(f'''
<div style="margin: 1rem 0; padding: 1rem; border: 2px solid #10b981; border-radius: 6px; background-color: #f0fdf4;">
<div style="font-weight: bold; color: #065f46; margin-bottom: 0.5rem;">ğŸ’¡ ä¸“ä¸šå»ºè®®</div>
<p style="margin: 0; color: #065f46; font-weight: bold;">{line}</p>
</div>''')
                
            else:
                # Regular paragraphs
                content_parts.append(f'<p style="margin: 0.5rem 0; padding: 0.25rem; line-height: 1.6; color: #374151;">{line}</p>')
        
        # Close any open section divs
        if content_parts and '<div style="margin: 1.5rem 0; padding: 1.5rem; border: 2px solid #e5e7eb' in str(content_parts):
            content_parts.append('</div>')
        
        content = '\n'.join(content_parts)
        
        # Create the structured simple report
        return f'''
<div style="max-width: 100%; margin: 0 auto; font-family: system-ui, -apple-system, sans-serif;">

<!-- Header Section -->
<div style="text-align: center; margin-bottom: 2rem; padding: 2rem; border: 2px solid #3b82f6; border-radius: 10px; background-color: #eff6ff;">
<h1 style="margin: 0 0 0.5rem 0; font-size: 1.8rem; font-weight: bold; color: #1e40af;">ğŸº å¤è‘£æ–‡ç‰©é‰´å®šæŠ¥å‘Š</h1>
<p style="margin: 0; color: #3730a3; font-weight: 600;">AIæ™ºèƒ½åˆ†æè¯„ä¼°</p>
<div style="margin-top: 1rem; padding: 0.5rem 1rem; background-color: #dbeafe; border-radius: 20px; display: inline-block;">
<span style="color: #1e40af; font-size: 0.9rem; font-weight: 600;">ğŸ“… {timestamp}</span>
</div>
</div>

<!-- Content Section -->
<div style="background-color: #ffffff; border: 1px solid #e5e7eb; border-radius: 8px; padding: 2rem;">
{content}
</div>

<!-- Footer Section -->
<div style="margin-top: 2rem; padding: 1.5rem; background-color: #f9fafb; border: 1px solid #e5e7eb; border-radius: 8px; text-align: center;">
<div style="padding: 1rem; border: 1px solid #d1d5db; border-radius: 6px; background-color: #ffffff;">
<p style="margin: 0; color: #374151; font-size: 0.9rem;">
<strong style="color: #dc2626;">âš ï¸ é‡è¦å£°æ˜ï¼š</strong> 
æœ¬æŠ¥å‘ŠåŸºäºAIæ·±åº¦å­¦ä¹ åˆ†æç”Ÿæˆï¼Œä»…ä¾›ä¸“ä¸šå‚è€ƒã€‚æœ€ç»ˆé‰´å®šç»“æœéœ€ç»“åˆå®ç‰©æ£€æµ‹ï¼Œå»ºè®®å’¨è¯¢æƒå¨å¤è‘£é‰´å®šæœºæ„è¿›è¡Œç¡®è®¤ã€‚
</p>
</div>
<div style="margin-top: 1rem; color: #6b7280; font-size: 0.8rem;">
<span style="margin: 0 1rem;">ğŸ¤– GPT-o3</span>
<span style="margin: 0 1rem;">ğŸ”’ å®‰å…¨</span>
<span style="margin: 0 1rem;">ğŸº ä¸“ä¸š</span>
</div>
</div>

</div>
'''