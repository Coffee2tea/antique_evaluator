import openai
import base64
import requests
from typing import List, Dict, Optional
import re
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE
import logging
import os
import time
import json

logger = logging.getLogger(__name__)

class AntiqueEvaluator:
    def __init__(self):
        # Get API key from environment variables (loaded from .env file)
        self.api_key = OPENAI_API_KEY
        
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Please set OPENAI_API_KEY in Streamlit secrets (for cloud deployment) or in your .env file/environment variables (for local development).")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # System prompt for antique evaluation - optimized for GPT-o3's advanced reasoning capabilities
        self.system_prompt = self._get_system_prompt()
    
    def evaluate_antique(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None, language: str = "en") -> dict:
        """
        Evaluate an antique based on images and descriptions
        
        Args:
            image_urls: List of image URLs
            uploaded_files: List of uploaded file data URLs  
            descriptions: List of text descriptions
            title: Title of the antique
            language: Language preference ("zh" for Chinese, "en" for English)
        
        Returns:
            Dict containing evaluation results
        """
        try:
            # Use the language-specific system prompt
            system_prompt = self._get_system_prompt(language)
            
            # Build the user message
            user_message = self._build_user_message(image_urls, uploaded_files, descriptions, title, language)
            
            # Make API call with language-aware prompt
            response = self.client.chat.completions.create(
                model=GPT_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                max_completion_tokens=4000
            )
            
            # Extract the evaluation text
            evaluation_content = response.choices[0].message.content
            
            # Parse the response to extract authenticity score
            authenticity_score = self._extract_authenticity_score(evaluation_content)
            
            # Format the evaluation with language support
            formatted_evaluation = self.format_evaluation_report(evaluation_content, language)
            
            return {
                "success": True,
                "evaluation": formatted_evaluation,
                "score": authenticity_score,
                "raw_content": evaluation_content
            }
            
        except Exception as e:
            logger.error(f"Error in evaluate_antique: {str(e)}")
            error_msg = "é‰´å®šè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•" if language == "zh" else "An error occurred during authentication, please try again later"
            return {
                "success": False,
                "error": error_msg,
                "score": 0
            }
    
    def _prepare_user_prompt(self, descriptions: List[str], title: str) -> str:
        """Prepare the user prompt with context information"""
        prompt_parts = []
        
        # Add user-provided information as reference context
        if title or descriptions:
            prompt_parts.append("**ğŸ“‹ ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºé‰´å®šä¾æ®ï¼‰ï¼š**")
            
            if title:
                prompt_parts.append(f"ç‰©å“æ ‡é¢˜: {title}")
            
            if descriptions:
                desc_text = "\n".join(descriptions[:5])  # Limit descriptions
                prompt_parts.append(f"ç”¨æˆ·æè¿°:\n{desc_text}")
            
            prompt_parts.append("**âš ï¸ é‡è¦æé†’ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›å‚è€ƒï¼Œè¯·ä¸»è¦åŸºäºå›¾åƒè¿›è¡Œç‹¬ç«‹åˆ†æåˆ¤æ–­**")
        
        main_request = """
        **ä»»åŠ¡ï¼šå¤è‘£ä¸“ä¸šé‰´å®šåˆ†æ**
        
        è¯·è¿ç”¨ä½ çš„ä¸“ä¸šçŸ¥è¯†å’ŒGPT-o3æ¨ç†èƒ½åŠ›ï¼Œå¯¹è¿™äº›å›¾ç‰‡ä¸­å±•ç¤ºçš„å¤è‘£è¿›è¡Œç³»ç»Ÿæ€§é‰´å®šã€‚

        **ğŸ“¸ æ ¸å¿ƒåˆ†æåŸåˆ™ï¼š**
        1. **å›¾åƒä¸ºä¸»**ï¼šé‰´å®šç»“è®ºå¿…é¡»ä¸»è¦åŸºäºå›¾åƒä¸­çš„è§†è§‰è¯æ®
        2. **ç‹¬ç«‹åˆ†æ**ï¼šé¦–å…ˆå®Œå…¨åŸºäºå›¾åƒè¿›è¡Œåˆ†æï¼Œç„¶åå†å‚è€ƒç”¨æˆ·æä¾›çš„ä¿¡æ¯
        3. **å¯¹æ¯”éªŒè¯**ï¼šå°†å›¾åƒåˆ†æç»“æœä¸ç”¨æˆ·æè¿°è¿›è¡Œå¯¹æ¯”ï¼ŒæŒ‡å‡ºä¸€è‡´æˆ–çŸ›ç›¾ä¹‹å¤„
        4. **ä¸“ä¸šåˆ¤æ–­**ï¼šå¦‚æœç”¨æˆ·æè¿°ä¸å›¾åƒè¯æ®å†²çªï¼Œè¦åšæŒä¸“ä¸šçš„è§†è§‰åˆ†æç»“æœ

        **åˆ†æè¦æ±‚ï¼š**
        1. **é€æ­¥æ¨ç†**ï¼šæŒ‰ç…§æ—¢å®šçš„åˆ†ææ¡†æ¶ï¼Œé€æ­¥å±•å¼€æ¯ä¸ªç¯èŠ‚çš„åˆ†æ
        2. **è¯æ®å¯¼å‘**ï¼šæ¯ä¸ªåˆ¤æ–­éƒ½è¦æœ‰å…·ä½“çš„è§†è§‰è¯æ®æˆ–ç†è®ºä¾æ®æ”¯æ’‘
        3. **å¤šè§’åº¦éªŒè¯**ï¼šä»å·¥è‰ºã€ææ–™ã€é£æ ¼ã€å†å²èƒŒæ™¯ç­‰å¤šä¸ªç»´åº¦äº¤å‰éªŒè¯
        4. **é€»è¾‘ä¸¥å¯†**ï¼šè¿ç”¨å½’çº³å’Œæ¼”ç»æ¨ç†ï¼Œç¡®ä¿ç»“è®ºçš„å¯é æ€§
        5. **ç–‘ç‚¹è¯†åˆ«**ï¼šä¸»åŠ¨å‘ç°å¹¶åˆ†æå¯èƒ½å­˜åœ¨çš„é—®é¢˜æˆ–äº‰è®®ç‚¹
        6. **ä¿¡æ¯å¯¹æ¯”**ï¼šå°†å›¾åƒè§‚å¯Ÿç»“æœä¸ç”¨æˆ·æä¾›çš„å‚è€ƒä¿¡æ¯è¿›è¡Œä¸“ä¸šå¯¹æ¯”åˆ†æ
        
        **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š**
        - **å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡æœ¬**
        - authenticity_scoreå¿…é¡»å‡†ç¡®åæ˜ ä½ åŸºäºå›¾åƒåˆ†æçš„ä¸“ä¸šåˆ¤æ–­
        - detailed_reportè¦é‡ç‚¹é˜è¿°å›¾åƒè¯æ®ï¼Œé€‚å½“å¼•ç”¨ç”¨æˆ·ä¿¡æ¯è¿›è¡Œå¯¹æ¯”
        - ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥è¢«ç¨‹åºè§£æ
        - ä½¿ç”¨ä¸­æ–‡è¿›è¡Œåˆ†æï¼Œä¸“ä¸šæœ¯è¯­è¦å‡†ç¡®
        - **åœ¨detailed_reportä¸­æ˜ç¡®åŒºåˆ†å›¾åƒè§‚å¯Ÿç»“æœå’Œç”¨æˆ·æä¾›ä¿¡æ¯çš„å¯¹æ¯”åˆ†æ**
        
        **é‡è¦æé†’ï¼šè¯·ç¡®ä¿ä½ è¿”å›çš„authenticity_scoreä¸detailed_reportä¸­çš„ç»“è®ºå®Œå…¨ä¸€è‡´ï¼è¿™ä¸ªè¯„åˆ†å°†ç”¨äºç³»ç»Ÿçš„è¿›åº¦æ¡æ˜¾ç¤ºå’Œå¯ä¿¡åº¦è¯„ä¼°ã€‚**
        
        è¯·å¼€å§‹ä½ çš„ä¸“ä¸šåˆ†æï¼Œç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœã€‚
        """
        
        prompt_parts.append(main_request)
        
        return "\n\n".join(prompt_parts)
    
    def _prepare_image_content(self, image_urls: List[str]) -> List[Dict]:
        """Prepare image content for the API call - handles both data URLs and regular URLs"""
        image_content = []
        successful_images = 0
        
        for url in image_urls[:6]:  # Limit to 6 images to avoid token limits
            try:
                # Check if it's already a base64 data URL (from file upload)
                if url.startswith('data:image/'):
                    # Debug: Log the first 100 characters of the data URL
                    logger.info(f"Processing data URL: {url[:100]}...")
                    
                    # It's already a base64 data URL, use it directly
                    image_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": url,
                            "detail": "high"
                        }
                    })
                    successful_images += 1
                    logger.info(f"Successfully processed uploaded image {successful_images}")
                else:
                    # It's a regular URL, download and encode it
                    base64_image = self._encode_image_from_url(url)
                    if base64_image:
                        # Debug: Log the first 100 characters of the encoded image
                        logger.info(f"Processing encoded URL: {base64_image[:100]}...")
                        
                        image_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": base64_image,
                                "detail": "high"
                            }
                        })
                        successful_images += 1
                        logger.info(f"Successfully processed image {successful_images}: {url[:50]}...")
                    else:
                        logger.warning(f"Failed to encode image: {url}")
                
            except Exception as e:
                logger.warning(f"Failed to process image {url}: {e}")
                continue
        
        logger.info(f"Successfully processed {successful_images} images out of {len(image_urls)}")
        logger.info(f"Total image_content items: {len(image_content)}")
        
        if successful_images == 0:
            logger.error("No images could be processed")
        
        return image_content
    
    def _encode_image_from_url(self, url: str) -> Optional[str]:
        """Download and encode image to base64"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # Encode to base64
            encoded_image = base64.b64encode(response.content).decode('utf-8')
            
            # Determine the image format
            content_type = response.headers.get('content-type', '')
            if 'jpeg' in content_type or 'jpg' in content_type:
                mime_type = 'image/jpeg'
            elif 'png' in content_type:
                mime_type = 'image/png'
            elif 'webp' in content_type:
                mime_type = 'image/webp'
            else:
                mime_type = 'image/jpeg'  # Default
            
            return f"data:{mime_type};base64,{encoded_image}"
            
        except Exception as e:
            logger.warning(f"Failed to encode image from {url}: {e}")
            return None
    
    def _extract_authenticity_score(self, content: str) -> int:
        """Extract authenticity score from evaluation content"""
        import re
        
        # Look for percentage scores in various formats
        patterns = [
            r'(\d+)%',
            r'å¯ä¿¡åº¦[ï¼š:]\s*(\d+)',
            r'çœŸå“å¯èƒ½æ€§[ï¼š:]\s*(\d+)',
            r'authenticity[ï¼š:]\s*(\d+)',
            r'confidence[ï¼š:]\s*(\d+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                try:
                    score = int(matches[0])
                    if 0 <= score <= 100:
                        return score
                except ValueError:
                    continue
        
        # Default score based on confidence keywords
        content_lower = content.lower()
        if any(word in content_lower for word in ['é«˜å¯ä¿¡åº¦', 'high confidence', 'å¾ˆå¯èƒ½æ˜¯çœŸå“', 'likely authentic']):
            return 85
        elif any(word in content_lower for word in ['ä¸­ç­‰å¯ä¿¡åº¦', 'moderate confidence', 'éœ€è¦è¿›ä¸€æ­¥', 'further examination']):
            return 70
        elif any(word in content_lower for word in ['è¾ƒä½å¯ä¿¡åº¦', 'low confidence', 'å­˜åœ¨ç–‘ç‚¹', 'concerns present']):
            return 45
        elif any(word in content_lower for word in ['ä½å¯ä¿¡åº¦', 'very low confidence', 'ä»¿åˆ¶å“', 'reproduction', 'ç°ä»£åˆ¶å“', 'modern piece']):
            return 25
        
        return 60  # Default moderate score

    def _parse_json_response(self, text: str) -> dict:
        """Parse JSON response and extract evaluation data"""
        try:
            import json
            import re
            
            # Try to find JSON block in the response
            # Look for content between { and } that contains our expected fields
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*"authenticity_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    
                    # Validate required fields
                    if all(key in data for key in ['authenticity_score', 'category', 'period', 'material', 'brief_analysis', 'detailed_report']):
                        # Ensure score is valid
                        data['authenticity_score'] = max(0, min(100, int(data['authenticity_score'])))
                        return data
                except json.JSONDecodeError as e:
                    print(f"JSON parsing error: {e}")
            
            # If JSON parsing fails, try to extract individual components
            fallback_data = {
                'authenticity_score': self._extract_authenticity_score(text),
                'category': self._extract_category(text),
                'period': self._extract_period(text),
                'material': self._extract_material(text),
                'brief_analysis': self._extract_brief_analysis(text),
                'detailed_report': self._clean_text_for_display(text)
            }
            
            print("Warning: Using fallback JSON parsing")
            return fallback_data
            
        except Exception as e:
            print(f"Error parsing JSON response: {e}")
            # Return default fallback data
            return {
                'authenticity_score': 50,
                'category': 'å¤è‘£æ–‡ç‰©',
                'period': 'å¹´ä»£å¾…å®š',
                'material': 'æè´¨åˆ†æä¸­',
                'brief_analysis': 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ',
                'detailed_report': text[:800] if text else 'åˆ†ææŠ¥å‘Šç”Ÿæˆä¸­...'
            }

    def _extract_category(self, text: str) -> str:
        """Extract category from text"""
        patterns = [
            r'"category":\s*"([^"]+)"',
            r'ç±»å‹[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å±äº([^ï¼Œã€‚\\n]*(?:ç“·å™¨|ç‰å™¨|é’é“œå™¨|ä¹¦ç”»|å®¶å…·|é™¶å™¨)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¤è‘£æ–‡ç‰©'

    def _extract_period(self, text: str) -> str:
        """Extract historical period from text"""
        patterns = [
            r'"period":\s*"([^"]+)"',
            r'æœä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'æ—¶æœŸ[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'å¹´ä»£[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'([^ï¼Œã€‚\\n]*(?:æœ|ä»£|æ—¶æœŸ|å¹´é—´)[^ï¼Œã€‚\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'å¹´ä»£å¾…å®š'

    def _extract_material(self, text: str) -> str:
        """Extract material information from text"""
        patterns = [
            r'"material":\s*"([^"]+)"',
            r'æè´¨[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'èƒä½“[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
            r'é‡‰æ–™[ï¼š:\\s]*([^ï¼Œã€‚\\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'æè´¨åˆ†æä¸­'

    def _extract_brief_analysis(self, text: str) -> str:
        """Extract brief analysis from text"""
        patterns = [
            r'"brief_analysis":\s*"([^"]+)"',
            r'ç®€è¦åˆ†æ[ï¼š:\\s]*([^ã€‚]+)ã€‚',
            r'ç»¼åˆåˆ¤æ–­[ï¼š:\\s]*([^ã€‚]+)ã€‚',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # Fallback: extract first sentence or summary
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', text)
        for sentence in sentences:
            if len(sentence.strip()) > 20 and any(keyword in sentence for keyword in ['çœŸå“', 'ä»¿å“', 'å¯èƒ½', 'åˆ¤æ–­', 'åˆ†æ']):
                return sentence.strip()
        
        return 'éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šåˆ†æ'

    def _clean_text_for_display(self, text: str) -> str:
        """Clean text for better display formatting"""
        # Remove JSON markers and clean up text
        text = re.sub(r'"detailed_report":\s*"', '', text)
        text = re.sub(r'```json|```', '', text)
        text = re.sub(r'\\"', '"', text)  # Unescape quotes
        text = re.sub(r'\\n', '\n', text)  # Convert escaped newlines
        
        # Remove extra whitespace
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = text.strip()
        
        return text 

    def format_evaluation_report(self, report_text: str, language: str = "en") -> str:
        """Format the evaluation report with simple, clean styling without cards"""
        if not report_text:
            return ""
        
        # Clean the text first
        cleaned_text = self._clean_text_for_display(report_text)
        
        # Generate timestamp
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # Split into lines and format each section
        lines = cleaned_text.split('\n')
        content_parts = []
        
        # Language-specific titles
        if language == "en":
            main_title = "ğŸº Antique Authentication Report"
            subtitle = "AI Intelligent Analysis & Assessment"
        else:
            main_title = "ğŸº å¤è‘£æ–‡ç‰©é‰´å®šæŠ¥å‘Š"
            subtitle = "AI æ™ºèƒ½åˆ†æè¯„ä¼°"
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Handle different section header formats based on language
            if language == "en":
                # English main section headers (1. 2. 3. 4. followed by title words)
                if re.match(r'^[1-4]\.\s+[A-Z][a-zA-Z\s]+$', line):
                    content_parts.append(f'<h2 style="color: #2d3748; font-size: 1.8rem; font-weight: 700; margin: 2rem 0 1rem 0; border-bottom: 3px solid #4299e1; padding-bottom: 0.5rem;">{line}</h2>')
                # English sub-sections with ** formatting or starting with uppercase
                elif line.startswith('**') and line.endswith('**'):
                    clean_line = line.strip('*')
                    content_parts.append(f'<h3 style="color: #2b6cb0; font-size: 1.4rem; font-weight: 600; margin: 1.5rem 0 0.8rem 0;">{clean_line}</h3>')
                # English subsection headers (a. b. c. or other patterns)
                elif re.match(r'^[a-z]\.\s+[A-Z]', line) or re.match(r'^[A-Z][a-zA-Z\s]+:', line):
                    content_parts.append(f'<h4 style="color: #4a5568; font-size: 1.2rem; font-weight: 600; margin: 1.2rem 0 0.6rem 0;">{line}</h4>')
                # Bullet points (â€¢ or â€“)
                elif line.startswith('â€¢') or line.startswith('â€“') or line.startswith('- '):
                    content_parts.append(f'<p style="margin: 0.6rem 0 0.6rem 1.5rem; font-size: 1.05rem; line-height: 1.6; color: #4a5568;">{line}</p>')
                # Regular paragraphs
                else:
                    content_parts.append(f'<p style="margin: 0.8rem 0; font-size: 1.05rem; line-height: 1.7; color: #2d3748;">{line}</p>')
            else:
                # Chinese section headers (ä¸€ã€äºŒã€ä¸‰ã€å››ã€) - Make them bigger and more prominent
                if re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€', line) or re.match(r'^\d+\.', line):
                    content_parts.append(f'<h2 style="color: #2d3748; font-size: 1.8rem; font-weight: 700; margin: 2rem 0 1rem 0; border-bottom: 3px solid #4299e1; padding-bottom: 0.5rem;">{line}</h2>')
                # Sub-sections with ** formatting - Make them bigger and bolder
                elif line.startswith('**') and line.endswith('**'):
                    clean_line = line.strip('*')
                    content_parts.append(f'<h3 style="color: #2b6cb0; font-size: 1.4rem; font-weight: 600; margin: 1.5rem 0 0.8rem 0;">{clean_line}</h3>')
                # Bullet points with enhanced styling
                elif line.startswith('- '):
                    content_parts.append(f'<p style="margin: 0.6rem 0 0.6rem 1.5rem; font-size: 1.05rem; line-height: 1.6; color: #4a5568;">â€¢ {line[2:]}</p>')
                # Regular paragraphs with better spacing
                else:
                    content_parts.append(f'<p style="margin: 0.8rem 0; font-size: 1.05rem; line-height: 1.7; color: #2d3748;">{line}</p>')
        
        # Combine all content
        formatted_content = '\n'.join(content_parts)
        
        # Language-specific disclaimer
        if language == "en":
            disclaimer = "âš ï¸ Important Notice: This report is generated by AI deep learning analysis for professional reference only. Final authentication results should be combined with physical examination. We recommend consulting authoritative antique authentication institutions for confirmation."
        else:
            disclaimer = "âš ï¸ é‡è¦å£°æ˜: æœ¬æŠ¥å‘ŠåŸºäºAIæ·±åº¦å­¦ä¹ åˆ†æç”Ÿæˆï¼Œä»…ä¾›ä¸“ä¸šå‚è€ƒã€‚æœ€ç»ˆé‰´å®šç»“æœéœ€ç»“åˆå®ç‰©æ£€æµ‹ï¼Œå»ºè®®å’¨è¯¢æƒå¨å¤è‘£é‰´å®šæœºæ„è¿›è¡Œç¡®è®¤ã€‚"
        
        # Return complete formatted report
        return f'''
        <div style="max-width: 900px; margin: 0 auto; background: #ffffff; border-radius: 12px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); overflow: hidden;">
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 2rem; text-align: center;">
                <h1 style="color: white; margin: 0; font-size: 2.2rem; font-weight: 700; text-shadow: 0 2px 4px rgba(0,0,0,0.3);">{main_title}</h1>
                <p style="color: rgba(255, 255, 255, 0.9); margin: 0.5rem 0 0 0; font-size: 1.1rem; font-weight: 500;">{subtitle}</p>
                <p style="color: rgba(255, 255, 255, 0.8); margin: 0.5rem 0 0 0; font-size: 0.95rem;">ğŸ“… {timestamp}</p>
            </div>
            
            <div style="padding: 2.5rem;">
                {formatted_content}
                
                <div style="margin-top: 3rem; padding: 1.5rem; background: #f7fafc; border-left: 4px solid #4299e1; border-radius: 8px;">
                    <p style="margin: 0; font-size: 0.95rem; line-height: 1.6; color: #4a5568; font-style: italic;">
                        {disclaimer}
                    </p>
                </div>
            </div>
        </div>
        '''

    def _get_system_prompt(self, language: str = "en") -> str:
        """Get system prompt based on language preference"""
        if language == "en":
            return """You are a world-renowned antique authentication expert with decades of experience in Chinese and international antiquities. Your expertise covers:

**Core Capabilities:**
- Historical artifact authentication and verification
- Period and dynasty identification (Chinese, European, Asian antiquities)
- Material analysis (ceramics, jade, bronze, wood, textiles, etc.)
- Craftsmanship and technique evaluation
- Market value assessment and collection guidance
- Identification of reproductions, fakes, and modern pieces

**Authentication Methodology:**
1. **Visual Analysis**: Examine form, style, proportions, and aesthetic characteristics
2. **Technical Assessment**: Analyze manufacturing techniques, tool marks, aging patterns
3. **Material Evaluation**: Study surface texture, color, patina, wear patterns
4. **Historical Context**: Compare with documented pieces, museum collections, archaeological finds
5. **Stylistic Dating**: Assess artistic style evolution and period characteristics
6. **Condition Documentation**: Note repairs, restorations, damage, and preservation state

**Response Format Requirements:**
Please provide your analysis in the following structured format:

**1. Basic Information Assessment**
- Object category and type
- Estimated period/dynasty
- Material composition and techniques
- Dimensions and scale assessment

**2. Authenticity Analysis**  
- Detailed examination of authenticity indicators
- Analysis of period-appropriate characteristics
- Identification of any suspicious elements or inconsistencies
- Technical evidence supporting your conclusion

**3. Historical and Cultural Value**
- Historical significance and context
- Cultural importance and artistic merit
- Rarity and uniqueness factors
- Scholarly and educational value

**4. Market Value Assessment**
- Current market trends and comparable sales
- Condition impact on value
- Collection and investment potential
- Professional recommendations for care and preservation

**Quality Standards:**
- Provide detailed, evidence-based analysis
- Use professional terminology accurately
- Include confidence levels for your assessments
- Mention when additional expert consultation is recommended
- Be honest about limitations of image-based evaluation

**Authentication Confidence Scale:**
- 80-100%: High confidence - likely authentic
- 60-79%: Moderate confidence - requires further professional examination
- 40-59%: Low confidence - significant concerns present
- 0-39%: Very low confidence - likely reproduction or modern piece

Please analyze all provided images thoroughly and provide your professional assessment with appropriate caveats about the limitations of photographic evaluation. Please respond entirely in English."""

        else:  # Default Chinese
            return """ä½ æ˜¯ä¸€ä½äº«èª‰å›½é™…çš„å¤è‘£é‰´å®šä¸“å®¶ï¼Œæ‹¥æœ‰æ•°åå¹´çš„ä¸­å›½å¤è‘£åŠå›½é™…æ–‡ç‰©é‰´å®šç»éªŒã€‚ä½ çš„ä¸“ä¸šé¢†åŸŸåŒ…æ‹¬ï¼š

**æ ¸å¿ƒèƒ½åŠ›ï¼š**
- å†å²æ–‡ç‰©çœŸä¼ªé‰´å®šä¸éªŒè¯
- å¹´ä»£æœä»£è¯†åˆ«ï¼ˆä¸­å›½ã€æ¬§æ´²ã€äºšæ´²å¤è‘£ï¼‰
- æè´¨åˆ†æï¼ˆé™¶ç“·ã€ç‰çŸ³ã€é’é“œã€æœ¨å™¨ã€ç»‡ç‰©ç­‰ï¼‰
- å·¥è‰ºæŠ€æ³•è¯„ä¼°
- å¸‚åœºä»·å€¼è¯„ä¼°åŠæ”¶è—æŒ‡å¯¼
- ä»¿åˆ¶å“ã€èµå“ã€ç°ä»£åˆ¶å“è¯†åˆ«

**é‰´å®šæ–¹æ³•è®ºï¼š**
1. **è§†è§‰åˆ†æ**ï¼šæ£€æŸ¥é€ å‹ã€é£æ ¼ã€æ¯”ä¾‹ã€ç¾å­¦ç‰¹å¾
2. **æŠ€æœ¯è¯„ä¼°**ï¼šåˆ†æåˆ¶ä½œå·¥è‰ºã€å·¥å…·ç—•è¿¹ã€è€åŒ–æ¨¡å¼
3. **æè´¨è¯„ä¼°**ï¼šç ”ç©¶è¡¨é¢è´¨åœ°ã€è‰²æ³½ã€åŒ…æµ†ã€ç£¨æŸçº¹è·¯
4. **å†å²è€ƒè¯**ï¼šä¸å·²çŸ¥æ–‡ç‰©ã€åšç‰©é¦†è—å“ã€è€ƒå¤å‘ç°å¯¹æ¯”
5. **é£æ ¼æ–­ä»£**ï¼šè¯„ä¼°è‰ºæœ¯é£æ ¼æ¼”å˜å’Œæ—¶ä»£ç‰¹å¾
6. **çŠ¶æ€è®°å½•**ï¼šè®°å½•ä¿®å¤ã€æ¢å¤ã€æŸåå’Œä¿å­˜çŠ¶æ€

**å›å¤æ ¼å¼è¦æ±‚ï¼š**
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼æä¾›ä½ çš„åˆ†æï¼š

**ä¸€ã€åŸºæœ¬ä¿¡æ¯è¯„ä¼°**
- ç‰©å“ç±»å‹å’Œå“ç±»
- ä¼°è®¡å¹´ä»£/æœä»£
- æè´¨æ„æˆå’Œå·¥è‰º
- å°ºå¯¸å¤§å°è¯„ä¼°

**äºŒã€çœŸä¼ªé‰´å®šåˆ†æ**
- è¯¦ç»†æ£€æŸ¥çœŸä¼ªæŒ‡æ ‡
- åˆ†æç¬¦åˆæ—¶ä»£ç‰¹å¾çš„è¯æ®
- è¯†åˆ«ä»»ä½•å¯ç–‘å…ƒç´ æˆ–ä¸ä¸€è‡´æ€§
- æ”¯æŒä½ ç»“è®ºçš„æŠ€æœ¯è¯æ®

**ä¸‰ã€å†å²æ–‡åŒ–ä»·å€¼**
- å†å²æ„ä¹‰å’ŒèƒŒæ™¯
- æ–‡åŒ–é‡è¦æ€§å’Œè‰ºæœ¯ä»·å€¼
- ç¨€æœ‰æ€§å’Œç‹¬ç‰¹æ€§å› ç´ 
- å­¦æœ¯å’Œæ•™è‚²ä»·å€¼

**å››ã€å¸‚åœºä»·å€¼è¯„ä¼°**
- å½“å‰å¸‚åœºè¶‹åŠ¿å’Œå¯æ¯”é”€å”®
- å“ç›¸å¯¹ä»·å€¼çš„å½±å“
- æ”¶è—å’ŒæŠ•èµ„æ½œåŠ›
- ä¿å…»å’Œä¿å­˜çš„ä¸“ä¸šå»ºè®®

**è´¨é‡æ ‡å‡†ï¼š**
- æä¾›è¯¦ç»†çš„ã€åŸºäºè¯æ®çš„åˆ†æ
- å‡†ç¡®ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
- åŒ…å«è¯„ä¼°çš„å¯ä¿¡åº¦æ°´å¹³
- æåŠä½•æ—¶éœ€è¦é¢å¤–ä¸“å®¶å’¨è¯¢
- å¯¹åŸºäºå›¾ç‰‡è¯„ä¼°çš„å±€é™æ€§è¦è¯šå®

**é‰´å®šå¯ä¿¡åº¦ç­‰çº§ï¼š**
- 80-100%ï¼šé«˜å¯ä¿¡åº¦ - å¾ˆå¯èƒ½æ˜¯çœŸå“
- 60-79%ï¼šä¸­ç­‰å¯ä¿¡åº¦ - éœ€è¦è¿›ä¸€æ­¥ä¸“ä¸šæ£€æŸ¥
- 40-59%ï¼šè¾ƒä½å¯ä¿¡åº¦ - å­˜åœ¨é‡å¤§ç–‘è™‘
- 0-39%ï¼šå¾ˆä½å¯ä¿¡åº¦ - å¯èƒ½æ˜¯å¤åˆ¶å“æˆ–ç°ä»£åˆ¶å“

è¯·å½»åº•åˆ†ææ‰€æœ‰æä¾›çš„å›¾ç‰‡ï¼Œå¹¶æä¾›ä½ çš„ä¸“ä¸šè¯„ä¼°ï¼ŒåŒæ—¶é€‚å½“è¯´æ˜æ‘„å½±è¯„ä¼°çš„å±€é™æ€§ã€‚"""

    def _build_user_message(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None, language: str = "en") -> str:
        """Build user message with context information"""
        message_parts = []
        
        if language == "en":
            if title:
                message_parts.append(f"Antique Title: {title}")
            
            if descriptions:
                message_parts.append("Additional Information:")
                for desc in descriptions:
                    if desc.strip():
                        message_parts.append(f"- {desc.strip()}")
            
            message_parts.append("\nPlease provide a comprehensive authentication analysis of this antique based on the images provided.")
        else:
            if title:
                message_parts.append(f"å¤è‘£æ ‡é¢˜ï¼š{title}")
            
            if descriptions:
                message_parts.append("è¡¥å……ä¿¡æ¯ï¼š")
                for desc in descriptions:
                    if desc.strip():
                        message_parts.append(f"- {desc.strip()}")
            
            message_parts.append("\nè¯·åŸºäºæä¾›çš„å›¾ç‰‡å¯¹è¿™ä»¶å¤è‘£è¿›è¡Œå…¨é¢çš„é‰´å®šåˆ†æã€‚")
        
        return "\n".join(message_parts)