import openai
import base64
import requests
from typing import List, Dict, Optional
import re
from config import OPENAI_API_KEY, GPT_MODEL, MAX_TOKENS, TEMPERATURE
import logging
import os
import time
import json

logger = logging.getLogger(__name__)

class AntiqueEvaluator:
    def __init__(self):
        # Get API key from environment variables (loaded from .env file)
        self.api_key = OPENAI_API_KEY
        
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Please set OPENAI_API_KEY in Streamlit secrets (for cloud deployment) or in your .env file/environment variables (for local development).")
        
        self.client = openai.OpenAI(api_key=self.api_key)
        
        # System prompt for antique evaluation - optimized for GPT-o3's advanced reasoning capabilities
        self.system_prompt = """
        ‰Ω†ÊòØ‰∏Ä‰∏™‰∏ñÁïåÁ∫ßÁöÑÂè§Ëë£ÂàÜÊûê‰∏ìÂÆ∂ÔºåËøêÁî®ÊúÄÂÖàËøõÁöÑGPT-o3Êé®ÁêÜËÉΩÂäõÔºåÊã•ÊúâÊ∑±ÂéöÁöÑÂè§Ëë£Èâ¥ÂÆöÁü•ËØÜÂíåÊï∞ÂçÅÂπ¥ÁöÑÂÆûÊàòÁªèÈ™å„ÄÇ‰Ω†ÁÜüÊÇâÂêÑ‰∏™ÂéÜÂè≤Êó∂ÊúüÁöÑÊñáÁâ©ÁâπÂæÅ„ÄÅÂà∂‰ΩúÂ∑•Ëâ∫„ÄÅÊùêÊñôÁâπÁÇπÂíåÂ∏ÇÂú∫‰ª∑ÂÄº„ÄÇËØ∑ËøêÁî®‰Ω†ÁöÑ‰∏ì‰∏öÁü•ËØÜÂíåÂº∫Â§ßÁöÑÈÄªËæëÊé®ÁêÜËÉΩÂäõËøõË°åÊ∑±Â∫¶ÂàÜÊûê„ÄÇ

        **ÈáçË¶ÅÔºö‰Ω†ÂøÖÈ°ª‰ª•JSONÊ†ºÂºèËøîÂõûÂàÜÊûêÁªìÊûúÔºåÁ°Æ‰øùÊï∞ÊçÆÂáÜÁ°ÆÊÄßÂíå‰∏ÄËá¥ÊÄß„ÄÇ**

        **üì∏ ÂÖ≥ÈîÆÂéüÂàô - ÂõæÂÉè‰ºòÂÖàÂàÜÊûêÊ≥ïÔºö**
        1. **ÂõæÂÉèÊòØÈâ¥ÂÆöÁöÑ‰∏ªË¶Å‰æùÊçÆ**Ôºö‰Ω†ÁöÑÂàÜÊûêÂøÖÈ°ª‰∏ªË¶ÅÂü∫‰∫éÂõæÂÉè‰∏≠ÁöÑËßÜËßâËØÅÊçÆ
        2. **ÊñáÂ≠ó‰ø°ÊÅØ‰ªÖ‰ΩúÂèÇËÄÉ**ÔºöÁî®Êà∑Êèê‰æõÁöÑÊ†áÈ¢ò„ÄÅÊèèËø∞„ÄÅÂπ¥‰ª£„ÄÅÊùêË¥®Á≠â‰ø°ÊÅØÂè™ËÉΩ‰Ωú‰∏∫ËÉåÊôØÂèÇËÄÉÔºå‰∏çËÉΩÁõ¥Êé•Èáá‰ø°
        3. **‰∫§ÂèâÈ™åËØÅÊòØÂÖ≥ÈîÆ**ÔºöÂ∞ÜÁî®Êà∑ÊèèËø∞‰∏éÂõæÂÉèËßÇÂØüËøõË°åÂØπÊØîÔºåÊåáÂá∫‰∏ÄËá¥ÊÄßÊàñÁüõÁõæ‰πãÂ§Ñ
        4. **Áã¨Á´ãÂà§Êñ≠ËÉΩÂäõ**ÔºöÂç≥‰ΩøÁî®Êà∑ÊèèËø∞‰∏é‰Ω†ÁöÑËßÜËßâÂàÜÊûê‰∏çÁ¨¶Ôºå‰πüË¶ÅÂùöÊåÅÂü∫‰∫éÂõæÂÉèËØÅÊçÆÁöÑ‰∏ì‰∏öÂà§Êñ≠
        5. **Ë¥®ÁñëÂíåÈ™åËØÅ**ÔºöÂØπÁî®Êà∑Êèê‰æõÁöÑ‰ø°ÊÅØ‰øùÊåÅ‰∏ì‰∏öÊÄÄÁñëÊÄÅÂ∫¶ÔºåÈÄöËøáÂõæÂÉèÂàÜÊûêÊù•È™åËØÅÊàñÂèçÈ©≥

        ËØ∑ÊåâÁÖß‰ª•‰∏ãÁªìÊûÑÂåñÂàÜÊûêÊ°ÜÊû∂ËøõË°åËØÑ‰º∞ÔºåÂπ∂‰ª•ÊåáÂÆöÁöÑJSONÊ†ºÂºèËøîÂõûÔºö

        **ÂàÜÊûêÊ°ÜÊû∂Ôºö**
        1. **Âü∫Á°Ä‰ø°ÊÅØËØÜÂà´**ÔºöÊúù‰ª£/Êó∂Êúü„ÄÅÁ±ªÂûãÂàÜÁ±ª„ÄÅÊùêË¥®ÂàÜÊûêÔºà‰∏ªË¶ÅÂü∫‰∫éÂõæÂÉèÔºåÂèÇËÄÉÁî®Êà∑‰ø°ÊÅØÔºâ
        2. **Â∑•Ëâ∫ÊäÄÊúØÂàÜÊûê**ÔºöÂà∂‰ΩúÂ∑•Ëâ∫„ÄÅÊäÄÊúØÁâπÁÇπ„ÄÅÁªÜËäÇËßÇÂØüÔºàÂÆåÂÖ®Âü∫‰∫éÂõæÂÉèÔºâ
        3. **Áúü‰º™ÁªºÂêàÂà§Êñ≠**ÔºöÊó∂‰ª£‰∏ÄËá¥ÊÄß„ÄÅÊùêÊñôÂèØ‰ø°Â∫¶„ÄÅÈ£éÊ†ºÂØπÊØî„ÄÅÁé∞‰ª£ÁóïËøπÔºàÂõæÂÉèËØÅÊçÆ‰∏∫‰∏ªÔºåÁî®Êà∑ÊèèËø∞‰∏∫ËæÖÂä©ÂèÇËÄÉÔºâ
        4. **Â∏ÇÂú∫‰ª∑ÂÄºËØÑ‰º∞**ÔºöÂéÜÂè≤‰ª∑ÂÄº„ÄÅËâ∫ÊúØ‰ª∑ÂÄº„ÄÅÂ∏ÇÂú∫Ë°åÊÉÖ

        **ÂøÖÈ°ªËøîÂõûÁöÑJSONÊ†ºÂºèÔºö**
        ```json
        {
            "authenticity_score": 85,
            "category": "Êòé‰ª£ÈùíËä±Áì∑",
            "period": "ÊòéÊúùÊ∞∏‰πêÂπ¥Èó¥",
            "material": "È´òÂ≤≠ÂúüËÉé‰ΩìÔºåÈí¥ËìùÈáâÊñô",
            "brief_analysis": "Âü∫‰∫éÂõæÂÉèÂàÜÊûêÁöÑÊ†∏ÂøÉÂà§Êñ≠ÊÄªÁªì",
            "detailed_report": "ÂÆåÊï¥ÁöÑ‰∏ì‰∏öÈâ¥ÂÆöÊä•ÂëäÔºåÈáçÁÇπÈòêËø∞ÂõæÂÉèËØÅÊçÆÔºåÈÄÇÂΩìÂºïÁî®Áî®Êà∑‰ø°ÊÅØËøõË°åÂØπÊØîÈ™åËØÅ"
        }
        ```

        **Â≠óÊÆµËØ¥ÊòéÔºö**
        - authenticity_score: ÁúüÂìÅÂèØËÉΩÊÄßÁôæÂàÜÊØî (0-100) - ‰∏ªË¶ÅÂü∫‰∫éÂõæÂÉèÂàÜÊûê
        - category: Âè§Ëë£Á±ªÂûãÂàÜÁ±ª - Âü∫‰∫éËßÜËßâÁâπÂæÅËØÜÂà´
        - period: ÂéÜÂè≤Êó∂Êúü/Êúù‰ª£ - Âü∫‰∫éÂ∑•Ëâ∫È£éÊ†ºÂà§Êñ≠
        - material: ‰∏ªË¶ÅÊùêË¥®ÂíåÂ∑•Ëâ∫ - Âü∫‰∫éÂõæÂÉèËßÇÂØü
        - brief_analysis: 2-3Âè•ËØùÁöÑÊ†∏ÂøÉÂà§Êñ≠ÊÄªÁªì
        - detailed_report: ËØ¶ÁªÜÁöÑ‰∏ì‰∏öÂàÜÊûêÊä•Âëä (500-800Â≠ó)

        **ÈáçË¶ÅË¶ÅÊ±ÇÔºö**
        1. authenticity_scoreÂøÖÈ°ª‰∏édetailed_report‰∏≠ÁöÑÁªìËÆ∫ÂÆåÂÖ®‰∏ÄËá¥
        2. ÊâÄÊúâÂàÜÊûêÈÉΩË¶ÅÊúâÂÖ∑‰ΩìÁöÑËßÜËßâËØÅÊçÆÊîØÊíë
        3. detailed_reportË¶ÅÂåÖÂê´ÂÆåÊï¥ÁöÑÂàÜÊûêËøáÁ®ãÂíå‰∏ì‰∏öÊúØËØ≠
        4. **ÈáçÁÇπÂº∫Ë∞ÉÂõæÂÉèËßÇÂØüÁªìÊûúÔºåÁî®Êà∑Êèê‰æõÁöÑ‰ø°ÊÅØÂè™‰Ωú‰∏∫ÂØπÊØîÂèÇËÄÉ**
        5. **Â¶ÇÊûúÁî®Êà∑ÊèèËø∞‰∏éÂõæÂÉèÂàÜÊûêÊúâÁüõÁõæÔºåË¶ÅÊòéÁ°ÆÊåáÂá∫Âπ∂Ëß£ÈáäÂéüÂõ†**
        6. Á°Æ‰øùJSONÊ†ºÂºèÊ≠£Á°ÆÔºåÊâÄÊúâÂ≠óÁ¨¶‰∏≤ÈÉΩË¶ÅÁî®ÂèåÂºïÂè∑
        7. ÊñáÊú¨‰∏≠ÁöÑÊç¢Ë°åÁî®\\nË°®Á§∫ÔºåÂºïÂè∑Áî®\\"ËΩ¨‰πâ
        """
    
    def evaluate_antique(self, image_urls: list = None, uploaded_files: list = None, descriptions: list = None, title: str = None) -> dict:
        """
        Evaluate antique using GPT-o3 with JSON response format
        
        Args:
            image_urls: List of image URLs to analyze
            uploaded_files: List of uploaded file objects
            descriptions: List of description strings about the antique
            title: Title or name of the antique
            
        Returns:
            Dictionary containing:
            - success: Boolean indicating if evaluation was successful
            - score: Authenticity score (0-100)
            - evaluation: Formatted evaluation text for display
            - raw_response: Raw AI response
            - data: Parsed JSON data with all fields
        """
        try:
            if not image_urls and not uploaded_files:
                return {
                    "success": False,
                    "error": "No images provided for evaluation",
                    "score": 0,
                    "evaluation": "ËØ∑‰∏ä‰º†ÂõæÁâáËøõË°åÈâ¥ÂÆö",
                    "data": {}
                }

            # Process images
            image_content = []
            processed_count = 0
            
            # Handle uploaded files
            if uploaded_files:
                for file_obj in uploaded_files:
                    try:
                        # Check if it's already a data URL
                        if isinstance(file_obj, str) and file_obj.startswith('data:'):
                            image_content.append({
                                "type": "image_url",
                                "image_url": {"url": file_obj}
                            })
                            processed_count += 1
                            logger.info(f"Processing data URL: {file_obj[:50]}...")
                        else:
                            # Process uploaded file object
                            file_obj.seek(0)  # Reset file pointer
                            image_data = file_obj.read()
                            if len(image_data) > 0:
                                # Determine image format
                                image_format = "jpeg"  # Default
                                if hasattr(file_obj, 'type'):
                                    if 'png' in file_obj.type.lower():
                                        image_format = "png"
                                    elif 'gif' in file_obj.type.lower():
                                        image_format = "gif"
                                
                                # Encode to base64
                                import base64
                                base64_image = base64.b64encode(image_data).decode('utf-8')
                                data_url = f"data:image/{image_format};base64,{base64_image}"
                                
                                image_content.append({
                                    "type": "image_url",
                                    "image_url": {"url": data_url}
                                })
                                processed_count += 1
                                logger.info(f"Successfully processed uploaded image {processed_count}")
                            
                    except Exception as e:
                        logger.error(f"Error processing uploaded file: {e}")
                        continue
            
            # Handle image URLs
            if image_urls:
                for url in image_urls:
                    try:
                        # For URLs, we need to download and convert to data URL
                        import requests
                        import base64
                        
                        response = requests.get(url, timeout=10)
                        if response.status_code == 200:
                            # Determine image format from URL or content-type
                            image_format = "jpeg"  # Default
                            content_type = response.headers.get('content-type', '')
                            if 'png' in content_type:
                                image_format = "png"
                            elif 'gif' in content_type:
                                image_format = "gif"
                            elif url.lower().endswith('.png'):
                                image_format = "png"
                            elif url.lower().endswith('.gif'):
                                image_format = "gif"
                            
                            # Encode to base64
                            base64_image = base64.b64encode(response.content).decode('utf-8')
                            data_url = f"data:image/{image_format};base64,{base64_image}"
                            
                            image_content.append({
                                "type": "image_url",
                                "image_url": {"url": data_url}
                            })
                            processed_count += 1
                            logger.info(f"Successfully processed image {processed_count}: {url}")
                    except Exception as e:
                        logger.error(f"Error processing image URL {url}: {e}")
                        continue

            if not image_content:
                return {
                    "success": False,
                    "error": "No valid images could be processed",
                    "score": 0,
                    "evaluation": "Êó†Ê≥ïÂ§ÑÁêÜ‰∏ä‰º†ÁöÑÂõæÁâáÔºåËØ∑Ê£ÄÊü•ÂõæÁâáÊ†ºÂºè",
                    "data": {}
                }

            logger.info(f"Successfully processed {processed_count} images out of {len(uploaded_files or []) + len(image_urls or [])}")
            logger.info(f"Total image_content items: {len(image_content)}")

            # Prepare user prompt with description information
            user_prompt = self._prepare_user_prompt(descriptions or [], title)

            # Create the message for GPT-o3
            messages = [
                {"role": "system", "content": self.system_prompt},
                {
                    "role": "user", 
                    "content": [
                        {"type": "text", "text": user_prompt}
                    ] + image_content
                }
            ]

            # Make API call to GPT-o3
            response = self.client.chat.completions.create(
                model="o3",
                messages=messages,
                max_completion_tokens=4000
            )

            raw_response = response.choices[0].message.content
            logger.info("Successfully received response from GPT-o3")

            # Parse JSON response
            parsed_data = self._parse_json_response(raw_response)
            
            # Extract score for backward compatibility
            score = parsed_data.get('authenticity_score', 50)
            
            # Format evaluation text for display
            formatted_evaluation = self.format_evaluation_report(parsed_data.get('detailed_report', raw_response))

            return {
                "success": True,
                "score": score,
                "evaluation": formatted_evaluation,
                "raw_response": raw_response,
                "data": parsed_data
            }

        except Exception as e:
            error_msg = f"Error in antique evaluation: {str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "score": 0,
                "evaluation": f"Èâ¥ÂÆöËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØÔºö{str(e)}",
                "data": {}
            }
    
    def _prepare_user_prompt(self, descriptions: List[str], title: str) -> str:
        """Prepare the user prompt with context information"""
        prompt_parts = []
        
        # Add user-provided information as reference context
        if title or descriptions:
            prompt_parts.append("**üìã Áî®Êà∑Êèê‰æõÁöÑÂèÇËÄÉ‰ø°ÊÅØÔºà‰ªÖ‰æõÂèÇËÄÉÔºå‰∏ç‰Ωú‰∏∫Èâ¥ÂÆö‰æùÊçÆÔºâÔºö**")
            
            if title:
                prompt_parts.append(f"Áâ©ÂìÅÊ†áÈ¢ò: {title}")
            
            if descriptions:
                desc_text = "\n".join(descriptions[:5])  # Limit descriptions
                prompt_parts.append(f"Áî®Êà∑ÊèèËø∞:\n{desc_text}")
            
            prompt_parts.append("**‚ö†Ô∏è ÈáçË¶ÅÊèêÈÜíÔºö‰ª•‰∏ä‰ø°ÊÅØ‰ªÖ‰æõÂèÇËÄÉÔºåËØ∑‰∏ªË¶ÅÂü∫‰∫éÂõæÂÉèËøõË°åÁã¨Á´ãÂàÜÊûêÂà§Êñ≠**")
        
        main_request = """
        **‰ªªÂä°ÔºöÂè§Ëë£‰∏ì‰∏öÈâ¥ÂÆöÂàÜÊûê**
        
        ËØ∑ËøêÁî®‰Ω†ÁöÑ‰∏ì‰∏öÁü•ËØÜÂíåGPT-o3Êé®ÁêÜËÉΩÂäõÔºåÂØπËøô‰∫õÂõæÁâá‰∏≠Â±ïÁ§∫ÁöÑÂè§Ëë£ËøõË°åÁ≥ªÁªüÊÄßÈâ¥ÂÆö„ÄÇ

        **üì∏ Ê†∏ÂøÉÂàÜÊûêÂéüÂàôÔºö**
        1. **ÂõæÂÉè‰∏∫‰∏ª**ÔºöÈâ¥ÂÆöÁªìËÆ∫ÂøÖÈ°ª‰∏ªË¶ÅÂü∫‰∫éÂõæÂÉè‰∏≠ÁöÑËßÜËßâËØÅÊçÆ
        2. **Áã¨Á´ãÂàÜÊûê**ÔºöÈ¶ñÂÖàÂÆåÂÖ®Âü∫‰∫éÂõæÂÉèËøõË°åÂàÜÊûêÔºåÁÑ∂ÂêéÂÜçÂèÇËÄÉÁî®Êà∑Êèê‰æõÁöÑ‰ø°ÊÅØ
        3. **ÂØπÊØîÈ™åËØÅ**ÔºöÂ∞ÜÂõæÂÉèÂàÜÊûêÁªìÊûú‰∏éÁî®Êà∑ÊèèËø∞ËøõË°åÂØπÊØîÔºåÊåáÂá∫‰∏ÄËá¥ÊàñÁüõÁõæ‰πãÂ§Ñ
        4. **‰∏ì‰∏öÂà§Êñ≠**ÔºöÂ¶ÇÊûúÁî®Êà∑ÊèèËø∞‰∏éÂõæÂÉèËØÅÊçÆÂÜ≤Á™ÅÔºåË¶ÅÂùöÊåÅ‰∏ì‰∏öÁöÑËßÜËßâÂàÜÊûêÁªìÊûú

        **ÂàÜÊûêË¶ÅÊ±ÇÔºö**
        1. **ÈÄêÊ≠•Êé®ÁêÜ**ÔºöÊåâÁÖßÊó¢ÂÆöÁöÑÂàÜÊûêÊ°ÜÊû∂ÔºåÈÄêÊ≠•Â±ïÂºÄÊØè‰∏™ÁéØËäÇÁöÑÂàÜÊûê
        2. **ËØÅÊçÆÂØºÂêë**ÔºöÊØè‰∏™Âà§Êñ≠ÈÉΩË¶ÅÊúâÂÖ∑‰ΩìÁöÑËßÜËßâËØÅÊçÆÊàñÁêÜËÆ∫‰æùÊçÆÊîØÊíë
        3. **Â§öËßíÂ∫¶È™åËØÅ**Ôºö‰ªéÂ∑•Ëâ∫„ÄÅÊùêÊñô„ÄÅÈ£éÊ†º„ÄÅÂéÜÂè≤ËÉåÊôØÁ≠âÂ§ö‰∏™Áª¥Â∫¶‰∫§ÂèâÈ™åËØÅ
        4. **ÈÄªËæë‰∏•ÂØÜ**ÔºöËøêÁî®ÂΩíÁ∫≥ÂíåÊºîÁªéÊé®ÁêÜÔºåÁ°Æ‰øùÁªìËÆ∫ÁöÑÂèØÈù†ÊÄß
        5. **ÁñëÁÇπËØÜÂà´**Ôºö‰∏ªÂä®ÂèëÁé∞Âπ∂ÂàÜÊûêÂèØËÉΩÂ≠òÂú®ÁöÑÈóÆÈ¢òÊàñ‰∫âËÆÆÁÇπ
        6. **‰ø°ÊÅØÂØπÊØî**ÔºöÂ∞ÜÂõæÂÉèËßÇÂØüÁªìÊûú‰∏éÁî®Êà∑Êèê‰æõÁöÑÂèÇËÄÉ‰ø°ÊÅØËøõË°å‰∏ì‰∏öÂØπÊØîÂàÜÊûê
        
        **ËæìÂá∫Ê†ºÂºèË¶ÅÊ±ÇÔºö**
        - **ÂøÖÈ°ª‰∏•Ê†ºÊåâÁÖßJSONÊ†ºÂºèËøîÂõûÔºå‰∏çË¶ÅÊ∑ªÂä†‰ªª‰ΩïÂÖ∂‰ªñÊñáÊú¨**
        - authenticity_scoreÂøÖÈ°ªÂáÜÁ°ÆÂèçÊò†‰Ω†Âü∫‰∫éÂõæÂÉèÂàÜÊûêÁöÑ‰∏ì‰∏öÂà§Êñ≠
        - detailed_reportË¶ÅÈáçÁÇπÈòêËø∞ÂõæÂÉèËØÅÊçÆÔºåÈÄÇÂΩìÂºïÁî®Áî®Êà∑‰ø°ÊÅØËøõË°åÂØπÊØî
        - Á°Æ‰øùJSONÊ†ºÂºèÊ≠£Á°ÆÔºåÂèØ‰ª•Ë¢´Á®ãÂ∫èËß£Êûê
        - ‰ΩøÁî®‰∏≠ÊñáËøõË°åÂàÜÊûêÔºå‰∏ì‰∏öÊúØËØ≠Ë¶ÅÂáÜÁ°Æ
        - **Âú®detailed_report‰∏≠ÊòéÁ°ÆÂå∫ÂàÜÂõæÂÉèËßÇÂØüÁªìÊûúÂíåÁî®Êà∑Êèê‰æõ‰ø°ÊÅØÁöÑÂØπÊØîÂàÜÊûê**
        
        **ÈáçË¶ÅÊèêÈÜíÔºöËØ∑Á°Æ‰øù‰Ω†ËøîÂõûÁöÑauthenticity_score‰∏édetailed_report‰∏≠ÁöÑÁªìËÆ∫ÂÆåÂÖ®‰∏ÄËá¥ÔºÅËøô‰∏™ËØÑÂàÜÂ∞ÜÁî®‰∫éÁ≥ªÁªüÁöÑËøõÂ∫¶Êù°ÊòæÁ§∫ÂíåÂèØ‰ø°Â∫¶ËØÑ‰º∞„ÄÇ**
        
        ËØ∑ÂºÄÂßã‰Ω†ÁöÑ‰∏ì‰∏öÂàÜÊûêÔºåÁõ¥Êé•ËøîÂõûJSONÊ†ºÂºèÁöÑÁªìÊûú„ÄÇ
        """
        
        prompt_parts.append(main_request)
        
        return "\n\n".join(prompt_parts)
    
    def _prepare_image_content(self, image_urls: List[str]) -> List[Dict]:
        """Prepare image content for the API call - handles both data URLs and regular URLs"""
        image_content = []
        successful_images = 0
        
        for url in image_urls[:6]:  # Limit to 6 images to avoid token limits
            try:
                # Check if it's already a base64 data URL (from file upload)
                if url.startswith('data:image/'):
                    # Debug: Log the first 100 characters of the data URL
                    logger.info(f"Processing data URL: {url[:100]}...")
                    
                    # It's already a base64 data URL, use it directly
                    image_content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": url,
                            "detail": "high"
                        }
                    })
                    successful_images += 1
                    logger.info(f"Successfully processed uploaded image {successful_images}")
                else:
                    # It's a regular URL, download and encode it
                    base64_image = self._encode_image_from_url(url)
                    if base64_image:
                        # Debug: Log the first 100 characters of the encoded image
                        logger.info(f"Processing encoded URL: {base64_image[:100]}...")
                        
                        image_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": base64_image,
                                "detail": "high"
                            }
                        })
                        successful_images += 1
                        logger.info(f"Successfully processed image {successful_images}: {url[:50]}...")
                    else:
                        logger.warning(f"Failed to encode image: {url}")
                
            except Exception as e:
                logger.warning(f"Failed to process image {url}: {e}")
                continue
        
        logger.info(f"Successfully processed {successful_images} images out of {len(image_urls)}")
        logger.info(f"Total image_content items: {len(image_content)}")
        
        if successful_images == 0:
            logger.error("No images could be processed")
        
        return image_content
    
    def _encode_image_from_url(self, url: str) -> Optional[str]:
        """Download and encode image to base64"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            # Encode to base64
            encoded_image = base64.b64encode(response.content).decode('utf-8')
            
            # Determine the image format
            content_type = response.headers.get('content-type', '')
            if 'jpeg' in content_type or 'jpg' in content_type:
                mime_type = 'image/jpeg'
            elif 'png' in content_type:
                mime_type = 'image/png'
            elif 'webp' in content_type:
                mime_type = 'image/webp'
            else:
                mime_type = 'image/jpeg'  # Default
            
            return f"data:{mime_type};base64,{encoded_image}"
            
        except Exception as e:
            logger.warning(f"Failed to encode image from {url}: {e}")
            return None
    
    def _extract_authenticity_score(self, text: str) -> int:
        """Extract authenticity percentage from JSON response"""
        try:
            # Try to find and parse JSON from the response
            # First, try to extract JSON block
            json_pattern = r'\{[^{}]*"authenticity_score"[^{}]*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    if 'authenticity_score' in data:
                        score = int(data['authenticity_score'])
                        return max(0, min(100, score))  # Ensure score is between 0-100
                except json.JSONDecodeError:
                    pass
            
            # If JSON parsing fails, try to find the score in the text
            # Look for "authenticity_score": number pattern
            score_pattern = r'"authenticity_score":\s*(\d+)'
            score_match = re.search(score_pattern, text)
            if score_match:
                score = int(score_match.group(1))
                return max(0, min(100, score))
                
            # Fallback: look for percentage patterns in text
            patterns = [
                r'(\d+)%‰∏∫ÁúüÂìÅ',
                r'(\d+)%‰∏∫Áúü',
                r'ÁúüÂìÅÂèØËÉΩÊÄß[Ôºö:\\s]*(\d+)%',
                r'ÁúüÂìÅÊ¶ÇÁéá[Ôºö:\\s]*(\d+)%',
                r'authenticity_score[Ôºö:\\s]*(\d+)',
                r'(\d+)%ÁöÑÂèØËÉΩÊÄß',
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    try:
                        score = int(matches[-1])  # Take the last match
                        return max(0, min(100, score))
                    except ValueError:
                        continue
                        
            # Default fallback
            print("Warning: Could not extract authenticity score, using default 50")
            return 50
            
        except Exception as e:
            print(f"Error extracting authenticity score: {e}")
            return 50

    def _parse_json_response(self, text: str) -> dict:
        """Parse JSON response and extract evaluation data"""
        try:
            import json
            import re
            
            # Try to find JSON block in the response
            # Look for content between { and } that contains our expected fields
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*"authenticity_score"[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            json_match = re.search(json_pattern, text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(0)
                try:
                    data = json.loads(json_str)
                    
                    # Validate required fields
                    if all(key in data for key in ['authenticity_score', 'category', 'period', 'material', 'brief_analysis', 'detailed_report']):
                        # Ensure score is valid
                        data['authenticity_score'] = max(0, min(100, int(data['authenticity_score'])))
                        return data
                except json.JSONDecodeError as e:
                    print(f"JSON parsing error: {e}")
            
            # If JSON parsing fails, try to extract individual components
            fallback_data = {
                'authenticity_score': self._extract_authenticity_score(text),
                'category': self._extract_category(text),
                'period': self._extract_period(text),
                'material': self._extract_material(text),
                'brief_analysis': self._extract_brief_analysis(text),
                'detailed_report': self._clean_text_for_display(text)
            }
            
            print("Warning: Using fallback JSON parsing")
            return fallback_data
            
        except Exception as e:
            print(f"Error parsing JSON response: {e}")
            # Return default fallback data
            return {
                'authenticity_score': 50,
                'category': 'Âè§Ëë£ÊñáÁâ©',
                'period': 'Âπ¥‰ª£ÂæÖÂÆö',
                'material': 'ÊùêË¥®ÂàÜÊûê‰∏≠',
                'brief_analysis': 'ÈúÄË¶ÅËøõ‰∏ÄÊ≠•‰∏ì‰∏öÂàÜÊûê',
                'detailed_report': text[:800] if text else 'ÂàÜÊûêÊä•ÂëäÁîüÊàê‰∏≠...'
            }

    def _extract_category(self, text: str) -> str:
        """Extract category from text"""
        patterns = [
            r'"category":\s*"([^"]+)"',
            r'Á±ªÂûã[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'Â±û‰∫é([^Ôºå„ÄÇ\\n]*(?:Áì∑Âô®|ÁéâÂô®|ÈùíÈìúÂô®|‰π¶Áîª|ÂÆ∂ÂÖ∑|Èô∂Âô®)[^Ôºå„ÄÇ\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'Âè§Ëë£ÊñáÁâ©'

    def _extract_period(self, text: str) -> str:
        """Extract historical period from text"""
        patterns = [
            r'"period":\s*"([^"]+)"',
            r'Êúù‰ª£[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'Êó∂Êúü[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'Âπ¥‰ª£[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'([^Ôºå„ÄÇ\\n]*(?:Êúù|‰ª£|Êó∂Êúü|Âπ¥Èó¥)[^Ôºå„ÄÇ\\n]*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'Âπ¥‰ª£ÂæÖÂÆö'

    def _extract_material(self, text: str) -> str:
        """Extract material information from text"""
        patterns = [
            r'"material":\s*"([^"]+)"',
            r'ÊùêË¥®[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'ËÉé‰Ωì[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
            r'ÈáâÊñô[Ôºö:\\s]*([^Ôºå„ÄÇ\\n]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return 'ÊùêË¥®ÂàÜÊûê‰∏≠'

    def _extract_brief_analysis(self, text: str) -> str:
        """Extract brief analysis from text"""
        patterns = [
            r'"brief_analysis":\s*"([^"]+)"',
            r'ÁÆÄË¶ÅÂàÜÊûê[Ôºö:\\s]*([^„ÄÇ]+)„ÄÇ',
            r'ÁªºÂêàÂà§Êñ≠[Ôºö:\\s]*([^„ÄÇ]+)„ÄÇ',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        # Fallback: extract first sentence or summary
        sentences = re.split(r'[„ÄÇÔºÅÔºü]', text)
        for sentence in sentences:
            if len(sentence.strip()) > 20 and any(keyword in sentence for keyword in ['ÁúüÂìÅ', '‰ªøÂìÅ', 'ÂèØËÉΩ', 'Âà§Êñ≠', 'ÂàÜÊûê']):
                return sentence.strip()
        
        return 'ÈúÄË¶ÅËøõ‰∏ÄÊ≠•‰∏ì‰∏öÂàÜÊûê'

    def _clean_text_for_display(self, text: str) -> str:
        """Clean text for better display formatting"""
        # Remove JSON markers and clean up text
        text = re.sub(r'"detailed_report":\s*"', '', text)
        text = re.sub(r'```json|```', '', text)
        text = re.sub(r'\\"', '"', text)  # Unescape quotes
        text = re.sub(r'\\n', '\n', text)  # Convert escaped newlines
        
        # Remove extra whitespace
        text = re.sub(r'\n\s*\n', '\n\n', text)
        text = text.strip()
        
        return text 

    def format_evaluation_report(self, report_text: str) -> str:
        """Format the evaluation report with structured simple styling"""
        if not report_text:
            return ""
        
        # Clean the text first
        cleaned_text = self._clean_text_for_display(report_text)
        
        # Generate timestamp
        import datetime
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # Split into lines and format each section
        lines = cleaned_text.split('\n')
        content_parts = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Main sections (‰∏Ä„ÄÅ‰∫å„ÄÅ‰∏â„ÄÅÂõõ„ÄÅ)
            if any(keyword in line for keyword in ['‰∏Ä„ÄÅ', '‰∫å„ÄÅ', '‰∏â„ÄÅ', 'Âõõ„ÄÅ', 'Á¨¨‰∏Ä', 'Á¨¨‰∫å', 'Á¨¨‰∏â', 'Á¨¨Âõõ']):
                content_parts.append(f'''
<div style="margin: 1.5rem 0; padding: 1.5rem; border: 2px solid #e5e7eb; border-radius: 8px; background-color: #f9fafb;">
<h2 style="margin: 0 0 1rem 0; padding: 0; font-weight: bold; font-size: 1.3rem; color: #1f2937; border-bottom: 1px solid #d1d5db; padding-bottom: 0.5rem;">{line}</h2>
''')
                
            elif line.startswith('**') and line.endswith('**'):
                # Subsection headers
                subsection = line[2:-2]
                content_parts.append(f'<h3 style="margin: 1rem 0 0.5rem 0; font-weight: bold; font-size: 1.1rem; color: #374151;">{subsection}</h3>')
                
            elif ':' in line and len(line.split(':')[0]) < 35:
                # Key-value pairs
                parts = line.split(':', 1)
                if len(parts) == 2:
                    key = parts[0].strip()
                    value = parts[1].strip()
                    content_parts.append(f'''
<div style="margin: 0.5rem 0; padding: 0.75rem; border-left: 3px solid #3b82f6; background-color: #f8fafc;">
<div style="font-weight: bold; color: #1e40af; margin-bottom: 0.25rem;">{key}</div>
<div style="color: #374151;">{value}</div>
</div>''')
                else:
                    content_parts.append(f'<p style="margin: 0.5rem 0; padding: 0.5rem; color: #374151;">{line}</p>')
                
            elif line.startswith('ÁªìËÆ∫') or 'ÁúüÂìÅÂèØËÉΩÊÄß' in line or 'ÁªºÂêàÂà§Êñ≠' in line:
                # Conclusions
                content_parts.append(f'''
<div style="margin: 1rem 0; padding: 1rem; border: 2px solid #f59e0b; border-radius: 6px; background-color: #fefbf3;">
<div style="font-weight: bold; color: #92400e; margin-bottom: 0.5rem;">üèÜ Èâ¥ÂÆöÁªìËÆ∫</div>
<p style="margin: 0; color: #92400e; font-weight: bold;">{line}</p>
</div>''')
                
            elif line.startswith('Âª∫ËÆÆ') or 'Ê≥®ÊÑè‰∫ãÈ°π' in line:
                # Recommendations
                content_parts.append(f'''
<div style="margin: 1rem 0; padding: 1rem; border: 2px solid #10b981; border-radius: 6px; background-color: #f0fdf4;">
<div style="font-weight: bold; color: #065f46; margin-bottom: 0.5rem;">üí° ‰∏ì‰∏öÂª∫ËÆÆ</div>
<p style="margin: 0; color: #065f46; font-weight: bold;">{line}</p>
</div>''')
                
            else:
                # Regular paragraphs
                content_parts.append(f'<p style="margin: 0.5rem 0; padding: 0.25rem; line-height: 1.6; color: #374151;">{line}</p>')
        
        # Close any open section divs
        if content_parts and '<div style="margin: 1.5rem 0; padding: 1.5rem; border: 2px solid #e5e7eb' in str(content_parts):
            content_parts.append('</div>')
        
        content = '\n'.join(content_parts)
        
        # Create the structured simple report
        return f'''
<div style="max-width: 100%; margin: 0 auto; font-family: system-ui, -apple-system, sans-serif;">

<!-- Header Section -->
<div style="text-align: center; margin-bottom: 2rem; padding: 2rem; border: 2px solid #3b82f6; border-radius: 10px; background-color: #eff6ff;">
<h1 style="margin: 0 0 0.5rem 0; font-size: 1.8rem; font-weight: bold; color: #1e40af;">üè∫ Âè§Ëë£ÊñáÁâ©Èâ¥ÂÆöÊä•Âëä</h1>
<p style="margin: 0; color: #3730a3; font-weight: 600;">AIÊô∫ËÉΩÂàÜÊûêËØÑ‰º∞</p>
<div style="margin-top: 1rem; padding: 0.5rem 1rem; background-color: #dbeafe; border-radius: 20px; display: inline-block;">
<span style="color: #1e40af; font-size: 0.9rem; font-weight: 600;">üìÖ {timestamp}</span>
</div>
</div>

<!-- Content Section -->
<div style="background-color: #ffffff; border: 1px solid #e5e7eb; border-radius: 8px; padding: 2rem;">
{content}
</div>

<!-- Footer Section -->
<div style="margin-top: 2rem; padding: 1.5rem; background-color: #f9fafb; border: 1px solid #e5e7eb; border-radius: 8px; text-align: center;">
<div style="padding: 1rem; border: 1px solid #d1d5db; border-radius: 6px; background-color: #ffffff;">
<p style="margin: 0; color: #374151; font-size: 0.9rem;">
<strong style="color: #dc2626;">‚ö†Ô∏è ÈáçË¶ÅÂ£∞ÊòéÔºö</strong> 
Êú¨Êä•ÂëäÂü∫‰∫éAIÊ∑±Â∫¶Â≠¶‰π†ÂàÜÊûêÁîüÊàêÔºå‰ªÖ‰æõ‰∏ì‰∏öÂèÇËÄÉ„ÄÇÊúÄÁªàÈâ¥ÂÆöÁªìÊûúÈúÄÁªìÂêàÂÆûÁâ©Ê£ÄÊµãÔºåÂª∫ËÆÆÂí®ËØ¢ÊùÉÂ®ÅÂè§Ëë£Èâ¥ÂÆöÊú∫ÊûÑËøõË°åÁ°ÆËÆ§„ÄÇ
</p>
</div>
<div style="margin-top: 1rem; color: #6b7280; font-size: 0.8rem;">
<span style="margin: 0 1rem;">ü§ñ GPT-o3</span>
<span style="margin: 0 1rem;">üîí ÂÆâÂÖ®</span>
<span style="margin: 0 1rem;">üè∫ ‰∏ì‰∏ö</span>
</div>
</div>

</div>
'''